(window.webpackJsonp=window.webpackJsonp||[]).push([[73],{309:function(e,t,r){"use strict";r.r(t);var a=r(28),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"ai-tasks-datasets"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#ai-tasks-datasets"}},[e._v("#")]),e._v(" AI Tasks & Datasets")]),e._v(" "),r("p",[e._v("Create Date: 2020.04.22")]),e._v(" "),r("p",[e._v("Last Update Date: 2020.04.22")]),e._v(" "),r("p",[e._v("By "),r("a",{attrs:{href:"https://yuweiyin.github.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("YuweiYin"),r("OutboundLink")],1)]),e._v(" "),r("h2",{attrs:{id:"自然语言处理-nlp-natural-language-processing"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#自然语言处理-nlp-natural-language-processing"}},[e._v("#")]),e._v(" 自然语言处理 NLP - Natural Language Processing")]),e._v(" "),r("h3",{attrs:{id:"glue-general-language-understanding-evaluation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#glue-general-language-understanding-evaluation"}},[e._v("#")]),e._v(" GLUE - General Language Understanding Evaluation")]),e._v(" "),r("table",[r("thead",[r("tr",[r("th",{staticStyle:{"text-align":"center"}},[e._v("DataSet")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("Full Name")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("Task")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("In Chinese")])])]),e._v(" "),r("tbody",[r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("CoLA")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Corpus of Linguistic Acceptability")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}}),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("句子语言性判断")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("SST-2")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Stanford Sentiment Treebank")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Sentiment analysis")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("情感分析")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("MRPC")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Microsoft Research Paraphrase Corpus")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic textual similarity")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("语义相似")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("STS-B")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic Textual Similarity")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic textual similarity")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("语义相似")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("QQP")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Quora Question Pairs")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic textual similarity/Paraphrase identification")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("语义文本相似性/问题对是否等价/释义识别")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("RTE")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Recognizing Texual Entailment")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("自然语言推断  文本蕴涵")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("MNLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Multi-Genre NLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("自然语言推断  多类型 NLI")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("QNLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Question NLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("自然语言推断  问答")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("WNLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Winograd NLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("自然语言推断  文本蕴涵")])])])]),e._v(" "),r("ul",[r("li",[e._v("相关链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1804.07461.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("GLUE paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://gluebenchmark.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("GLUE dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e",target:"_blank",rel:"noopener noreferrer"}},[e._v("GLUE Download Script"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://w4ngatang.github.io/static/papers/superglue.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"cola-the-corpus-of-linguistic-acceptability"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#cola-the-corpus-of-linguistic-acceptability"}},[e._v("#")]),e._v(" CoLA - The Corpus of Linguistic Acceptability")]),e._v(" "),r("p",[e._v("CoLA 是纽约大学发布的有关语法的数据集，该任务主要是对一个给定句子，判定其是否语法正确，因此 CoLA 属于单个句子的文本二分类任务。")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1805.12471.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("CoLA paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://nyu-mll.github.io/CoLA/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CoLA dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.nyu.edu/projects/bowman/xnli/XNLI-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: cola_public 1.0"),r("OutboundLink")],1),e._v(" (260 KB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://s3.amazonaws.com/xnli/XNLI-MT-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: cola_public 1.1"),r("OutboundLink")],1),e._v(" (255 KB, ZIP)")])])])]),e._v(" "),r("h3",{attrs:{id:"sst-stanford-sentiment-treebank"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sst-stanford-sentiment-treebank"}},[e._v("#")]),e._v(" SST - Stanford Sentiment Treebank")]),e._v(" "),r("p",[e._v("SST 是斯坦福大学发布的一个情感分析数据集，主要针对电影评论来做情感分类，因此SST属于单个句子的文本分类任务。其中 SST-2 是二分类，SST-5 是五分类，SST-5 的情感极性区分的更细致。")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("SST paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/sentiment/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("SST dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Main zip file with readme"),r("OutboundLink")],1),e._v(" (6.4 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://nlp.stanford.edu/~socherr/stanfordSentimentTreebankRaw.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Dataset raw counts"),r("OutboundLink")],1),e._v(" (4.8 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Train, Dev, Test Splits in PTB Tree Format"),r("OutboundLink")],1),e._v(" (790 KB, ZIP)")])])])]),e._v(" "),r("h3",{attrs:{id:"mrpc-microsoft-research-paraphrase-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#mrpc-microsoft-research-paraphrase-corpus"}},[e._v("#")]),e._v(" MRPC - Microsoft Research Paraphrase Corpus")]),e._v(" "),r("p",[e._v("MRPC 由微软发布，判断两个给定句子是否具有相同的语义，属于句子对的文本二分类任务。MRPC 提供 5081 对英文句子，这些句子是从网络上的新闻源中提取的，还有人工注释，指示每对是否捕获了释义/语义等价关系。从任何给定的新闻文章中提取的句子不超过1个。我们已作出协调一致的努力，正确地将每个句子信息与其出处以及有关其作者的任何相关信息相关联。")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d3/data/pdf/anthology-PDF/C/C04/C04-1051.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("MRPC paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.microsoft.com/en-us/download/confirmation.aspx?id=52398",target:"_blank",rel:"noopener noreferrer"}},[e._v("MRPC Download"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"sts-semantic-textual-similarity"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sts-semantic-textual-similarity"}},[e._v("#")]),e._v(" STS - Semantic Textual Similarity")]),e._v(" "),r("p",[e._v("使用语义文本相似性（STS）来衡量句子的意义相似性。")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1708.00055.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("STS paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark",target:"_blank",rel:"noopener noreferrer"}},[e._v("STS Download"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"nli-natural-language-inference"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#nli-natural-language-inference"}},[e._v("#")]),e._v(" NLI - Natural Language Inference")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1809.05053.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("XNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.nyu.edu/projects/bowman/multinli/paper.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("MultiNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/pubs/snli_paper.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("SNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("e-SNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1808.06752.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.nyu.edu/projects/bowman/xnli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("XNLI dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.nyu.edu/projects/bowman/multinli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MultiNLI dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/projects/snli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("SNLI dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://jgc128.github.io/mednli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.nyu.edu/projects/bowman/xnli/XNLI-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: XNLI 1.0"),r("OutboundLink")],1),e._v(" (17 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://s3.amazonaws.com/xnli/XNLI-MT-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: XNLI-MT 1.0"),r("OutboundLink")],1),e._v(" (445 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.nyu.edu/projects/bowman/multinli/multinli_1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: MultiNLI 1.0"),r("OutboundLink")],1),e._v(" (227 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/projects/snli/snli_1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: SNLI 1.0"),r("OutboundLink")],1),e._v(" (~100 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://doi.org/10.13026/C2RS98",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: MedNLI"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("相关源码：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/OanaMariaCamburu/e-SNLI",target:"_blank",rel:"noopener noreferrer"}},[e._v("e-SNLI code"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://archive.physionet.org/physiotools/mimic-code/mednli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI code"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://github.com/jgc128/mednli_baseline",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI baseline"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"squad"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#squad"}},[e._v("#")]),e._v(" SQuAD")]),e._v(" "),r("p",[e._v("SQuAD 是斯坦福大学于 2016 年推出的机器阅读理解（Machine Reading Comprehension, MRC）数据集。输入一篇文章以及相应一些问题，需要模型输出问题的答案。此数据集所有文章选自 Wikipedia 维基百科，数据集的量为当今其他数据集（例如 WikiQA）的几十倍之多。一共有 107,785 问题，以及配套的 536 篇文章。")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/abs/1606.05250",target:"_blank",rel:"noopener noreferrer"}},[e._v("SQuAD 1"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://arxiv.org/abs/1806.03822",target:"_blank",rel:"noopener noreferrer"}},[e._v("SQuAD 2"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集链接：\n"),r("ul",[r("li",[e._v("https://rajpurkar.github.io/SQuAD-explorer/")])])])]),e._v(" "),r("h3",{attrs:{id:"wikitext"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wikitext"}},[e._v("#")]),e._v(" WikiText")]),e._v(" "),r("p",[e._v("WikiText 英语词库数据（The WikiText Long Term Dependency Language Modeling Dataset）是一个包含 一亿个词汇的英文词库数据，这些词汇是从 Wikipedia 的优质文章和标杆文章中提取得到，包括 WikiText-2 和 WikiText-103 两个版本，相比于著名的 Penn Treebank (PTB) 词库中的词汇数量，前者是其 2 倍，后者是其 110 倍。每个词汇还同时保留产生该词汇的原始文章，这尤其适合当需要长时依赖（longterm dependency）自然语言建模的场景。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：\n"),r("ul",[r("li",[e._v("http://metamind.io/research/the-wikitext-long-term-dependency-language-modeling-dataset/")]),e._v(" "),r("li",[e._v("https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip")])])])]),e._v(" "),r("h3",{attrs:{id:"imdb"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#imdb"}},[e._v("#")]),e._v(" IMDB")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Learning Word Vectors for Sentiment Analysis"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ai.stanford.edu/~amaas/data/sentiment/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Large Movie Review Dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ai.stanford.edu/~amaas/data/sentiment/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Large Movie Review Dataset v1.0"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"sentiment140"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sentiment140"}},[e._v("#")]),e._v(" Sentiment140")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Twitter Sentiment Classification using Distant Supervision"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://help.sentiment140.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sentiment140"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://help.sentiment140.com/for-students",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sentiment140 For Academics"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Stanford link"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://docs.google.com/file/d/0B04GJPshIjmPRnZManQwWEdTZjg/edit",target:"_blank",rel:"noopener noreferrer"}},[e._v("Google Drive link"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"wordnet"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wordnet"}},[e._v("#")]),e._v(" WordNet")]),e._v(" "),r("ul",[r("li",[e._v("WordNet 链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://mitpress.mit.edu/books/wordnet",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet An Electronic Lexical Database"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://wordnet.princeton.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://wordnet.princeton.edu/download/current-version",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet current version"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://wordnet.princeton.edu/download/old-versions",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet old version"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"the-wikipedia-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#the-wikipedia-corpus"}},[e._v("#")]),e._v(" The Wikipedia Corpus")]),e._v(" "),r("ul",[r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.english-corpora.org/wiki/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Wikipedia Corpus"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.corpusdata.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Full-text corpus data"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"the-blog-authorship-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#the-blog-authorship-corpus"}},[e._v("#")]),e._v(" The Blog Authorship Corpus")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.cs.biu.ac.il/~schlerj/schler_springsymp06.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Effects of Age and Gender on Blogging"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Blog Authorship Corpus"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.cs.biu.ac.il/~koppel/blogs/blogs.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: The Blog Authorship Corpus"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"wmt-statistical-machine-translation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wmt-statistical-machine-translation"}},[e._v("#")]),e._v(" WMT - Statistical Machine Translation")]),e._v(" "),r("p",[r("a",{attrs:{href:"http://www.statmt.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Statistical Machine Translation"),r("OutboundLink")],1)]),e._v(" "),r("ul",[r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt19/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WMT 19"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt20/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WMT 20"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://statmt.org/europarl/",target:"_blank",rel:"noopener noreferrer"}},[e._v("uropean Parliament Proceedings Parallel Corpus 1996-2011"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt19/translation-task.html#download",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download WMT19"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt20/translation-task.html#download",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download WMT20"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"uci-s-spambase"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#uci-s-spambase"}},[e._v("#")]),e._v(" UCI’s Spambase")]),e._v(" "),r("p",[e._v("来自 UCI 的经典垃圾电子邮件数据集。这是一个大型垃圾邮件数据集，用于垃圾邮件过滤。")]),e._v(" "),r("p",[e._v("链接：https://archive.ics.uci.edu/ml/datasets/Spambase")]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"计算机视觉-cv-computer-vision"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#计算机视觉-cv-computer-vision"}},[e._v("#")]),e._v(" 计算机视觉 CV - Computer Vision")]),e._v(" "),r("h3",{attrs:{id:"mnist"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#mnist"}},[e._v("#")]),e._v(" MNIST")]),e._v(" "),r("p",[e._v("MNIST 数据集来自美国国家标准与技术研究所，National Institute of Standards and Technology (NIST)。训练集 (training set) 由来自 250 个不同人手写的数字构成，其中 50% 是高中学生，50% 来自人口普查局 (the Census Bureau) 的工作人员。测试集(test set) 也是同样比例的手写数字数据。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：\n"),r("ul",[r("li",[e._v("http://pjreddie.com/projects/mnist-in-csv/")]),e._v(" "),r("li",[e._v("http://yann.lecun.com/exdb/mnist/")])])])]),e._v(" "),r("h3",{attrs:{id:"mnist-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#mnist-2"}},[e._v("#")]),e._v(" MNIST")]),e._v(" "),r("p",[e._v("MNIST 数据集来自美国国家标准与技术研究所，National Institute of Standards and Technology (NIST)。训练集 (training set) 由来自250个不同人手写的数字构成，其中 50% 是高中学生，50% 来自人口普查局 (the Census Bureau) 的工作人员。测试集(test set) 也是同样比例的手写数字数据。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：\n"),r("ul",[r("li",[e._v("http://pjreddie.com/projects/mnist-in-csv/")]),e._v(" "),r("li",[e._v("http://yann.lecun.com/exdb/mnist/")])])])]),e._v(" "),r("h3",{attrs:{id:"fashion-mnist"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#fashion-mnist"}},[e._v("#")]),e._v(" Fashion-MNIST")]),e._v(" "),r("p",[e._v("Fashion-MNIST 包含 60,000个训练图像和 10,000 个测试图像，它是一个类似 MNIST 的时尚产品数据库。开发人员认为 MNIST 已被过度使用，因此他们将其作为该数据集的直接替代品。每张图片都以灰度显示，并与10个类别的标签相关联。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/zalandoresearch/fashion-mnist",target:"_blank",rel:"noopener noreferrer"}},[e._v("fashion-mnist Github"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"cifar-10"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#cifar-10"}},[e._v("#")]),e._v(" CIFAR-10")]),e._v(" "),r("p",[e._v("CIFAR-10 数据集由 10 个类的 60000 张 32x32 彩色图像组成，每个类有 6000 张图像。其中含有 50000 张训练图像和 10000 张测试图像。数据集分为五个训练批次和一个测试批次，每个批次有 10000 张图像。测试批次包含来自每个类别的恰好 1000 个随机选择的图像。训练批次以随机顺序包含剩余图像，但一些训练批次可能包含来自一个类别的图像比另一个更多。总体来说，五个训练集之和包含来自每个类的 5000 张图像。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：https://www.cs.toronto.edu/~kriz/cifar.html")])]),e._v(" "),r("h3",{attrs:{id:"imagenet"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#imagenet"}},[e._v("#")]),e._v(" ImageNet")]),e._v(" "),r("p",[e._v("图像处理界最有名的图像数据集之一，一般情况下只用子数据集（如 MiniImageNet）就可以。ImageNet 数据集是为了促进计算机图像识别技术的发展而设立的一个大型图像数据集。其图片数量最多，分辨率最高，含有的类别更多，有上千个图像类别。每年 ImageNet 的项目组织都会举办一场ImageNet大规模视觉识别竞赛，从而会诞生许多图像识别模型。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：http://image-net.org/")])]),e._v(" "),r("h3",{attrs:{id:"open-images-dataset-v4"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#open-images-dataset-v4"}},[e._v("#")]),e._v(" Open Images Dataset V4")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：https://github.com/openimages/dataset")])]),e._v(" "),r("h3",{attrs:{id:"coco-common-objects-in-context"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#coco-common-objects-in-context"}},[e._v("#")]),e._v(" COCO - Common Objects in Context")]),e._v(" "),r("ul",[r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://cocodataset.org/#home",target:"_blank",rel:"noopener noreferrer"}},[e._v("Common Objects in Context"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://cocodataset.org/#download",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Images & Annotations"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("相关源码：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/cocodataset",target:"_blank",rel:"noopener noreferrer"}},[e._v("cocodataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://github.com/cocodataset/cocoapi",target:"_blank",rel:"noopener noreferrer"}},[e._v("cocoapi"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"vqa-visual-qa"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#vqa-visual-qa"}},[e._v("#")]),e._v(" VQA - Visual QA")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1612.00837.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://visualqa.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Visual QA"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://visualqa.org/vqa_v1_download.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: VQA v1"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://visualqa.org/download.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: VQA v2"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"visual-genome"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#visual-genome"}},[e._v("#")]),e._v(" Visual Genome")]),e._v(" "),r("p",[e._v("非常详细的视觉知识库，并带有 100K 图像的深字幕。相较于 ImageNet 数据集，这个数据集每张图片所包含的信息更加丰富，将对象、属性之间的关系做注解，是这套数据集的核心。Visual Genome 数据集采用了微软 COCO 的图片库，用极丰富的细节对这十万张图片做了注解。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：http://visualgenome.org/")])]),e._v(" "),r("h3",{attrs:{id:"svhn-street-view-house-numbers"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#svhn-street-view-house-numbers"}},[e._v("#")]),e._v(" SVHN - Street View House Numbers")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reading Digits in Natural Images with Unsupervised Feature Learning"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Street View House Numbers (SVHN) Dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[e._v("Format 1: Full Numbers\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/train.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: train.tar.gz"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/test.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: test.tar.gz"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/extra.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: extra.tar.gz"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Format 2: Cropped Digits\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/train_32x32.mat",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: train_32x32.mat"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/test_32x32.mat",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: test_32x32.mat"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: extra_32x32.mat"),r("OutboundLink")],1)])])])])])]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"语音-speech"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#语音-speech"}},[e._v("#")]),e._v(" 语音 Speech")]),e._v(" "),r("h3",{attrs:{id:"librispeech"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#librispeech"}},[e._v("#")]),e._v(" LibriSpeech")]),e._v(" "),r("p",[e._v("该数据集是包含大约 1000 小时的英语语音的大型语料库。这些数据来自 LibriVox 项目的有声读物。它已被分割并正确对齐，如果你正在寻找一个起点，请查看已准备好的声学模型，这些模型在 kaldi-asr.org 和语言模型上进行了训练，适合评估。")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.danielpovey.com/files/2015_icassp_librispeech.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("LibriSpeech: an ASR corpus based on public domain audio books"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.openslr.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Open Speech and Language Resources"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/12/",target:"_blank",rel:"noopener noreferrer"}},[e._v("LibriSpeech ASR corpus"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/dev-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("dev-clean.tar.gz"),r("OutboundLink")],1),e._v(' [337M]   (development set, "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/dev-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/dev-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("dev-other.tar.gz"),r("OutboundLink")],1),e._v(' [314M]   (development set, "other", more challenging, speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/dev-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/test-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("test-clean.tar.gz"),r("OutboundLink")],1),e._v(' [346M]   (test set, "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/test-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/test-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("test-other.tar.gz"),r("OutboundLink")],1),e._v(' [328M]   (test set, "other" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/test-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/train-clean-100.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("train-clean-100.tar.gz"),r("OutboundLink")],1),e._v(' [6.3G]   (training set of 100 hours "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/train-clean-100.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/train-clean-360.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("train-clean-360.tar.gz"),r("OutboundLink")],1),e._v(' [23G]   (training set of 360 hours "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/train-clean-360.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/train-other-500.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("train-other-500.tar.gz"),r("OutboundLink")],1),e._v(' [30G]   (training set of 500 hours "other" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/train-other-500.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/intro-disclaimers.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("intro-disclaimers.tar.gz"),r("OutboundLink")],1),e._v(" [695M]   (extracted LibriVox announcements for some of the speakers )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/intro-disclaimers.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/original-mp3.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("original-mp3.tar.gz"),r("OutboundLink")],1),e._v(" [87G]   (LibriVox mp3 files, from which corpus' audio was extracted )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/original-mp3.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/original-books.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("original-books.tar.gz"),r("OutboundLink")],1),e._v(" [297M]   (Project Gutenberg texts, against which the audio in the corpus was aligned )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/original-books.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/raw-metadata.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("raw-metadata.tar.gz"),r("OutboundLink")],1),e._v(" [33M]   (Some extra meta-data produced during the creation of the corpus )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/raw-metadata.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/md5sum.txt",target:"_blank",rel:"noopener noreferrer"}},[e._v("md5sum.txt"),r("OutboundLink")],1),e._v(" [600 bytes]   (MD5 checksums for the archive files )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/md5sum.txt",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"voxceleb"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#voxceleb"}},[e._v("#")]),e._v(" VoxCeleb")]),e._v(" "),r("ul",[r("li",[e._v("原论文链接：\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.robots.ox.ac.uk/~vgg/publications/2017/Nagrani17/nagrani17.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb: a large-scale speaker identification dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集首页：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("数据集下载：\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb1"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb2"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"voxforge"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#voxforge"}},[e._v("#")]),e._v(" VoxForge")]),e._v(" "),r("p",[e._v("带口音英语的清晰语音数据集。如果你需要有强大的不同口音、语调识别能力，会比较有用，可以提高系统的鲁棒性。")]),e._v(" "),r("ul",[r("li",[e._v("相关链接：http://www.voxforge.org/")])]),e._v(" "),r("h3",{attrs:{id:"msd-million-song-dataset"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#msd-million-song-dataset"}},[e._v("#")]),e._v(" MSD - Million Song Dataset")]),e._v(" "),r("ul",[r("li",[r("p",[e._v("原论文链接：")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://www.deepdyve.com/lp/association-for-computing-machinery/the-million-song-dataset-challenge-C1ThXUlRZH",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Million Song Dataset Challenge"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[r("p",[e._v("数据集首页：")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"http://millionsongdataset.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Million Song Dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[r("p",[e._v("数据集下载：")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"http://millionsongdataset.com/pages/getting-dataset/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: MSD"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("TODO")])]),e._v(" "),r("ul",[r("li",[e._v("数据集描述（数据量级、样例数据）")]),e._v(" "),r("li",[e._v("相关经典、SOTA 模型，及其效果分数表格")])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);