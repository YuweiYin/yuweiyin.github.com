(window.webpackJsonp=window.webpackJsonp||[]).push([[326],{573:function(e,a,r){"use strict";r.r(a);var t=r(28),n=Object(t.a)({},(function(){var e=this,a=e.$createElement,r=e._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"plm-roberta"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#plm-roberta"}},[e._v("#")]),e._v(" PLM - RoBERTa")]),e._v(" "),r("p",[e._v("Natural Language Processing - "),r("a",{attrs:{href:"https://github.com/YuweiYin",target:"_blank",rel:"noopener noreferrer"}},[e._v("YuweiYin"),r("OutboundLink")],1)]),e._v(" "),r("hr"),e._v(" "),r("p",[r("em",[r("strong",[e._v("RoBERTa")])])]),e._v(" "),r("p",[r("strong",[e._v("paper")]),e._v(": RoBERTa: A Robustly Optimized BERT Pretraining Approach")]),e._v(" "),r("ul",[r("li",[e._v("Author: Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov")]),e._v(" "),r("li",[e._v("Paper Link: "),r("a",{attrs:{href:"https://arxiv.org/abs/1907.11692",target:"_blank",rel:"noopener noreferrer"}},[e._v("arXiv"),r("OutboundLink")],1)]),e._v(" "),r("li",[e._v("Paper Download: "),r("a",{attrs:{href:"https://arxiv.org/pdf/1907.11692",target:"_blank",rel:"noopener noreferrer"}},[e._v("arXiv"),r("OutboundLink")],1)])]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v("@article{liu2019roberta,\n  title={Roberta: A robustly optimized bert pretraining approach},\n  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},\n  journal={arXiv preprint arXiv:1907.11692},\n  year={2019}\n}\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);