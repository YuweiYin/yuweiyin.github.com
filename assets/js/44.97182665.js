(window.webpackJsonp=window.webpackJsonp||[]).push([[44],{256:function(t,s,a){"use strict";a.r(s);var n=a(28),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"algorithm-graph-theory-push-relabel"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#algorithm-graph-theory-push-relabel"}},[t._v("#")]),t._v(" Algorithm - Graph Theory - Push-Relabel")]),t._v(" "),a("p",[t._v("Create Date: 2020.06.04")]),t._v(" "),a("p",[t._v("Last Update Date: 2020.06.04")]),t._v(" "),a("p",[t._v("By "),a("a",{attrs:{href:"https://yuweiyin.github.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("YuweiYin"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),a("p",[t._v("最大流 Max-Flow")]),t._v(" "),a("p",[t._v("推送-重贴标签算法 Push-Relabel")]),t._v(" "),a("h3",{attrs:{id:"流网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#流网络"}},[t._v("#")]),t._v(" 流网络")]),t._v(" "),a("p",[t._v("流网络 G = (V, E) 是一个有向图，图中每条边 (u, v) \\in E 有一个"),a("strong",[t._v("非负")]),t._v("的"),a("strong",[t._v("容量值")]),t._v(" c(u, v) >= 0。而且，如果边集合 E 包含一条边 (u, v)，则图中不存在反方向的边 (v, u)。如果 (u, v) \\notin E，为方便起见，定义 c(u, v) = 0。并且在图中不允许有自循环/自圈 (u, u)。")]),t._v(" "),a("p",[t._v("另外，在流网络的所有结点中，有两个特殊的结点："),a("strong",[t._v("源结点")]),t._v(" s (source) 和"),a("strong",[t._v("汇点")]),t._v(" t (terminal)。源结点入度为 0、汇点出度为 0。为方便起见，假定 V 中每个结点 v 都位于某条从 s 到 v 的路径上，即有 "),a("code",[t._v("s ~> v ~> t")]),t._v(" 路径。")]),t._v(" "),a("p",[t._v("因此，流网络图是"),a("strong",[t._v("弱连通")]),t._v("的。并且由于除源结点 s 外的每个结点都至少有一条进入的边，有 "),a("code",[t._v("|E| >= |V| - 1")]),t._v("。")]),t._v(" "),a("ul",[a("li",[t._v("流网络的性质主要如下：\n"),a("ul",[a("li",[t._v("流网络 G = (V, E) 是一个弱连通的有向图")]),t._v(" "),a("li",[t._v("所有边的权重为非负值，且每条边的权重值有上界 c(u, v)")]),t._v(" "),a("li",[t._v("任意两个结点 u, v \\in V，不能同时存在边 (u, v) 和边 (v, u)")]),t._v(" "),a("li",[t._v("如果某边 (u, v) 不存在，定义其权重值 c(u, v) = 0")]),t._v(" "),a("li",[t._v("图中没有自循环 (u, u)")]),t._v(" "),a("li",[t._v("通常来说，源结点 s 的入度为 0，汇点 t 的出度为 0")]),t._v(" "),a("li",[t._v("每个结点 v 都处于从 s 到 t 的某条路径上。即：从起点 s 发出的流量可以流经 v 到达终点 t")])])])]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/max-flow-1.png",alt:"max-flow-1"}})]),t._v(" "),a("p",[t._v("这里给出流的形式化定义。设 G = (V, E) 是一个"),a("strong",[t._v("流网络")]),t._v("，其"),a("strong",[t._v("容量函数")]),t._v("为 c。设 s 为网络的"),a("strong",[t._v("源结点")]),t._v("，t 为"),a("strong",[t._v("汇点")]),t._v("。G 中的"),a("strong",[t._v("流")]),t._v("是一个"),a("strong",[t._v("实值函数")]),t._v(" f: VxV -> R，满足如下两条性质：")]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("容量限制")]),t._v("：（“流量有限额”）对于所有的结点 u, v \\in V，要求 0 <= f(u, v) <= c(u, v)")]),t._v(" "),a("li",[a("strong",[t._v("流量守恒")]),t._v("：（“流入等于流出”）对于所有的结点 u \\in V - {s, t}，要求 $ \\sum_{v \\in V} f(v, u) = \\sum_{v \\in V} f(u, v) $\n"),a("ul",[a("li",[t._v("当 (u, v) \\notin E 时，从结点 u 到结点 v 之间没有流，因此 f(u, v) == 0")])])])]),t._v(" "),a("p",[t._v("称非负数值 f(u, v) 为从结点 u 到结点 v 的流。一个流 f 的值 "),a("code",[t._v("|f|")]),t._v(" 定义如下：")]),t._v(" "),a("p",[t._v("$$ |f| = \\sum_{v \\in V} f(s, v) = \\sum_{v \\in V} f(v, s) $$")]),t._v(" "),a("p",[t._v("即，流 f 的值时从源结点流出的总流量 减去 流入源结点的总流量。这里符号 "),a("code",[t._v("|·|")]),t._v(" 仅用作表达流的值，而不是数的绝对值或者集合的基数值。")]),t._v(" "),a("p",[t._v("通常来说，一个流网络不会有任何进入源结点的边，即源结点的入度为 0，故求和项 $ \\sum_{v \\in V} f(v, s) $ 的值将是 0。但对于有的网络而言（比如"),a("strong",[t._v("残存网络")]),t._v("），流入源结点的流量十分重要。")]),t._v(" "),a("p",[t._v("在"),a("strong",[t._v("最大流问题")]),t._v("中，给定一个"),a("strong",[t._v("流网络")]),t._v(" G、一个"),a("strong",[t._v("源结点")]),t._v(" s、一个"),a("strong",[t._v("汇点")]),t._v(" t，目标是找到值最大的一个"),a("strong",[t._v("流")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"推送-重贴标签算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#推送-重贴标签算法"}},[t._v("#")]),t._v(" 推送-重贴标签算法")]),t._v(" "),a("p",[t._v("许多"),a("strong",[t._v("渐近效率很高")]),t._v("的最大流算法都是“推送-重贴标签”算法，最大流算法的"),a("strong",[t._v("最快实现")]),t._v("也是基于此方法。另外，此方法还能有效地解决其它流问题，如"),a("strong",[t._v("最小成本流")]),t._v("问题。")]),t._v(" "),a("p",[t._v("首先引入 Goldberg 的“通用”最大流算法，该算法有一个非常简单的实现，其运行时间为 "),a("code",[t._v("O(|V|^2 |E|)")]),t._v("，这比基于 "),a("a",{attrs:{href:"./ford-fulkerson"}},[t._v("Ford-Fulkerson 方法")]),t._v(" 的 Edmonds-Karp 算法的运行时间 "),a("code",[t._v("O(|V| |E|^2)")]),t._v(" 要好。对此通用算法进行调优，可以获得运行时间为 "),a("code",[t._v("O(|V|^3)")]),t._v(" 的"),a("strong",[t._v("前置重贴标签算法")]),t._v(" (Relabel-To-Front)。")]),t._v(" "),a("p",[t._v("推送-重贴标签算法比 Ford-Fulkerson 方法的"),a("strong",[t._v("局域性更强")]),t._v("。它不是对整个残存网络 Gf 进行检查、然后选择一条增广路径，而是一个结点一个结点地进行考察，"),a("strong",[t._v("每一步只检查当前结点的邻结点")]),t._v("。而且，与 Ford-Fulkerson 方法不同，推送-重贴标签算法并不在整个执行过程中保持流量守恒性质，而是在执行过程中维持一个 "),a("strong",[t._v("预流")]),t._v(" (preflow)。预流是一个 V x V -> R 的函数 f，该函数满足"),a("strong",[t._v("容量限制性质")]),t._v(" 以及如下 "),a("strong",[t._v("弱化了的流量守恒性质")]),t._v("：")]),t._v(" "),a("p",[t._v("对于所有的结点 u \\in V - {s}，有 $ e(u) = \\sum_{v \\in V} f(v, u) - \\sum_{v \\in V} f(u, v) >= 0 $。即：进入一个结点的流 可以超过流出该结点的流。此差值 e(u) 被称为进入结点 u 的 "),a("strong",[t._v("超额流")]),t._v(" (excess flow)。如果对于结点 u \\in V - {s}，有 e(u) > 0，则称该结点 "),a("strong",[t._v("溢出")]),t._v(" (overflowing)。")]),t._v(" "),a("h3",{attrs:{id:"基本操作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本操作"}},[t._v("#")]),t._v(" 基本操作")]),t._v(" "),a("p",[t._v("推送-重贴标签算法的两个基本操作：“推送”预流、对结点进行“重贴标签”。")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("推送预流")]),t._v("：从一个结点 将超额的流 推送到一个 (高度更低的) 邻结点。\n"),a("ul",[a("li",[t._v("预流只能从高度较高的结点 推送到高低较低的邻结点。")])])]),t._v(" "),a("li",[a("strong",[t._v("重贴标签")]),t._v("：改变一个结点的标签 (即该结点的高度)。\n"),a("ul",[a("li",[t._v("如果一个结点 u 有超额流，但是 u 的邻结点的高度 均大于 u 的高度，此时需要将 u 的高度提升至 "),a("strong",[t._v("残余容量")]),t._v(" cf(u ,v) > 0 的"),a("strong",[t._v("最矮邻结点")]),t._v(" v 的高度加一，从而可以把 u 的超额流经过边 (u, v) 推送给邻居结点 v。")])])])]),t._v(" "),a("p",[t._v("结点"),a("strong",[t._v("高度")]),t._v("的准确定义：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 的一个预流。如果函数 h: V -> N 满足 h(s) = "),a("code",[t._v("|V|")]),t._v(" 且 h(t) = 0，并且对于所有残存网络 Gf 中的边 (u, v) \\in Ef，均有 h(u) <= h(v) + 1，则 h 是一个"),a("strong",[t._v("高度函数")]),t._v("。")]),t._v(" "),a("p",[t._v("在有的文献中，高度函数也通常被称为“距离函数”，一个结点的高度也被称为“距离标签”。这里使用“高度”，更能体现水往低处流的直观思想，帮助理解算法的过程。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.12")]),t._v("：设 G = (V, E) 为一个流网络，设 f 为 G 的预流，设 h 为 V 上的高度函数。对于任意两个结点 u, v \\in V，如果 h(u) > h(v) + 1，则 (u, v) 不是残存网络 Gf 中的一条边。")]),t._v(" "),a("h3",{attrs:{id:"基本操作-推送操作"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本操作-推送操作"}},[t._v("#")]),t._v(" 基本操作-推送操作")]),t._v(" "),a("p",[t._v("如果结点 u 是一个溢出结点，即 e(u) > 0。此时，如果对于 u 的邻结点 v，有如下两个性质：")]),t._v(" "),a("ul",[a("li",[t._v("残存网络中残存容量 cf(u ,v) > 0。（这保证了边 (u, v) 还能够负载更多的流量）")]),t._v(" "),a("li",[t._v("h(u) = h(v) + 1。（一定要注意：预流推送操作 仅针对高度差为 1 的两结点进行）")])]),t._v(" "),a("p",[t._v("若存在这样的邻居结点 v，则可以执行下述 "),a("code",[t._v("PUSH(u, v)")]),t._v(" 过程将 u 的超额流推动给 v。下面的伪代码所执行的任务是对预流 f 和结点 u 和 v 的超额流进行更新。该过程假定可以在给定 u 和 f 的情况下，能在常数时间内计算出残存容量 cf(u, v)。另外，将存放在结点 u 上的超额流保存在属性 u.e 上，将 u 的高度(标签)保存在属性 u.h 中。表达式 $ \\delta_f (u, v) $ 是一个临时变量，用来存放可以从 u 推送到 v 的流量。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("PUSH(u, v)\n1  // Applies when: u is overflowing, cf(u, v) > 0, and u.h = v.h + 1\n2  // Action: Push \\delta_f(u, v) = min(u.e, cf(u, v)) units of the flow from u to v\n3  \\delta_f(u, v) = min(u.e, cf(u, v))\n4  if (u, v) \\in E\n5      (u, v).f = (u, v).f + \\delta_f(u, v)\n6  else\n7      (v, u).f = (v, u).f - \\delta_f(u, v)\n8  u.e = u.e - \\delta_f(u, v)\n9  v.e = v.e + \\delta_f(u, v)\n")])])]),a("p",[t._v("由于推送到结点 v 的流量是 min(u.e, cf(u, v))，所以不会导致超额流 u.e < 0，也不会使得边 (u, v) 的流量超过其容量限制。"),a("code",[t._v("PUSH(u, v)")]),t._v(" 在 4～7 行更新残存网络的边 (u, v) 和 (v, u) 的残存容量 cf 值。在 8～9 行更新进入结点 u 和 v 的超额流，即 e 属性。")]),t._v(" "),a("p",[a("code",[t._v("PUSH(u, v)")]),t._v(" 仅允许在高度情况为 u.h = v.h + 1 时进行推送。另外根据引理 26.12，高度差超过 1 的两个结点之间也不应存在残存边。")]),t._v(" "),a("p",[t._v("称 "),a("code",[t._v("PUSH(u, v)")]),t._v(" 为从结点 u 结点 v 的一个推送操作。如果一个推送操作适用于有向边 (u, v)，则称推送操作适用于结点 u。如果在该操作后，残存网络中的边 (u, v) 达到 "),a("strong",[t._v("饱和状态")]),t._v("（即在操作之后有 cf(u, v) == 0），则该推送操作被称为 "),a("strong",[t._v("饱和推送")]),t._v("，否则该操作被称为 "),a("strong",[t._v("非饱和推送")]),t._v("。另外，如果一条边达到饱和状态，它将从残存网络中消失。（具体实现时，残存网络矩阵中 不考虑 cf(u, v) 为 0 的边即可）")]),t._v(" "),a("p",[t._v("根据 "),a("code",[t._v("\\delta_f(u, v) = min(u.e, cf(u, v))")]),t._v(" 可知，当 cf(u, v) <= u.e 时，此推送是饱和推送；否则为非饱和推送，此时 "),a("code",[t._v("\\delta_f(u, v) = u.e")]),t._v("，因此推送操作结束后，结点 u 不再溢出（即下面的引理 26.13）。而且，如果 cf(u, v) == u.e，那么此操作不仅是饱和操作，还能够在推送结束后让 u.e 变为 0，表示消除了结点 u 的溢出状态。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.13")]),t._v("：在从结点 u 到结点 v 的一个非饱和推送操作后，结点 u 将不再溢出。")]),t._v(" "),a("h3",{attrs:{id:"基本操作-重贴标签"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本操作-重贴标签"}},[t._v("#")]),t._v(" 基本操作-重贴标签")]),t._v(" "),a("p",[t._v("如果结点 u 溢出，并且其邻居结点的高度均不低于 u 的高度 u.h，即对所有的边 (u, v) \\in Ef，有 u.h <= v.h，则如下伪代码描述的基本操作 "),a("code",[t._v("RELABEL(u)")]),t._v(" 适用于结点 u。通过将结点 u "),a("strong",[t._v("提升到适当的高度")]),t._v("，让它可以把溢出的超额流推动给邻居结点。即让 "),a("code",[t._v("PUSH(u, v)")]),t._v(" 操作适用于有向边 (u, v)、适用于结点 u。（另外，根据定义，源结点 s 和汇点 t 都不可能溢出，所以 "),a("code",[t._v("RELABEL")]),t._v(" 操作不会适用于 s 和 t）")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("RELABEL(u)\n1  // Applies when: u is overflowing and for all v \\in V such that (u, v) \\in Ef, u.h <= v.h\n2  // Action: Increase the height of u\n3  u.h = 1 + min(v.h: (u, v) \\in Ef)\n")])])]),a("p",[a("code",[t._v("RELABEL")]),t._v(" 过程的条件中描述的 "),a("code",[t._v("(u, v) \\in Ef")]),t._v("，隐含了残存容量 cf(u, v) > 0。")]),t._v(" "),a("p",[t._v("当调用操作 "),a("code",[t._v("RELABEL(u)")]),t._v(" 时，称结点 u "),a("strong",[t._v("被重贴标签")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"通用的推送-重贴标签算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#通用的推送-重贴标签算法"}},[t._v("#")]),t._v(" 通用的推送-重贴标签算法")]),t._v(" "),a("p",[t._v("通用的推送-重贴标签算法 使用子程序 "),a("code",[t._v("INITIALIZE_PREFLOW(G, s)")]),t._v(" 在流网络中创建一个由如下公式定义的初始预流：")]),t._v(" "),a("ul",[a("li",[t._v("若 u == s，则 (u, v).f = c(u, v)")]),t._v(" "),a("li",[t._v("若 u != s，则 (u, v).f = 0")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("INITIALIZE_PREFLOW(G, s)\n1  for each vertex v \\in G.V\n2      v.h = 0\n3      v.e = 0\n4  for each edge(u, v) \\in G.E\n5      (u, v).f = 0\n6  s.h = |G.V|\n7  for each vertex v \\in s.Adj\n8      (s, v).f = c(s, v)\n9      v.e = c(s, v)\n10     s.e = s.e - c(s, v)\n")])])]),a("p",[t._v("该初始化过程 将从源结点 s 发出的所有边都充满流（即理想上 最大流的最大可能取值，也即是切割 ({s}, V-{s}) 的容量），而其它边上都没有流。对于每个与源结点 s 相邻的结点 v，一开始其超额流 v.e = c(s, v)，因为流入 v 的流量是 c(s, v)，而流出 v 的流量为 0。并且将 s.e 初始化为所有这些容量之和的相反数。至于高度(标签)，一开始仅有源结点 s 高度为 "),a("code",[t._v("|V|")]),t._v("，其余结点的高度均为 0。")]),t._v(" "),a("p",[t._v("进行初始化过程后，按非特定次序执行一个序列的推送和重贴标签操作，就能得出如下"),a("strong",[t._v("通用算法")]),t._v("：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("GENERIC_PUSH_RELABEL(G, s, t)\n1  INITIALIZE_PREFLOW(G, s)\n2  while there exists an applicable push or relabel operation\n3      select an applicable push or relabel operation and perform it\n")])])]),a("p",[t._v("下面的引理说明，"),a("strong",[t._v("只要存在溢出结点")]),t._v("，两种基本操作就"),a("strong",[t._v("至少一种可以应用")]),t._v("到该溢出结点上。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.14")]),t._v("（可以对溢出结点执行推送或重贴标签操作）：设 G = （V, E) 是一个源结点为 s、汇点为 t 的流网络，设 f 为一个预流，h 为 f 的任意高度函数。如果 u 是一个溢出结点，则要么可以对结点 u 执行推送操作，要么可以对其执行重贴标签操作。")]),t._v(" "),a("h3",{attrs:{id:"通用推送-重贴标签算法的正确性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#通用推送-重贴标签算法的正确性"}},[t._v("#")]),t._v(" 通用推送-重贴标签算法的正确性")]),t._v(" "),a("p",[t._v("为了证明通用的推送-重贴标签算法能够解决最大流问题，下面首先证明"),a("strong",[t._v("如果该算法终止")]),t._v("，"),a("strong",[t._v("预流 f 就是一个最大流")]),t._v("。然后再证明该算法必将终止。下面首先关注高度函数 h。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.15")]),t._v("（"),a("strong",[t._v("结点高度从来不会降低")]),t._v("）：在一个流网络 G = (V, E) 上执行 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 算法的过程中，对于每个结点 u \\in V，其高度 v.h 从来不会减少。而且，每当一个重贴标签操作应用到结点 u 时，其高度 u.h 至少增加一个单位。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.16")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，则 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 算法在 G 上执行的过程中，将"),a("strong",[t._v("维持")]),t._v("属性 h 作为一个"),a("strong",[t._v("高度函数")]),t._v("的各性质。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.17")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 中的一个预流，h 为 V 上的一个高度函数。那么在残存网络 Gf 中不存在一条从源结点 s 到汇点 t 的路径。（即不存在增广路径）")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-1.png",alt:"push-relabel-1"}})]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("定理 26.18")]),t._v("（通用的推送-重贴标签方法的"),a("strong",[t._v("正确性")]),t._v("）：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，如果算法 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 在图 G 上运行时"),a("strong",[t._v("能够终止")]),t._v("，则该算法所计算出的预流 f 是图 G 的"),a("strong",[t._v("一个最大流")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-2.png",alt:"push-relabel-2"}})]),t._v(" "),a("h3",{attrs:{id:"通用推送-重贴标签算法的分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#通用推送-重贴标签算法的分析"}},[t._v("#")]),t._v(" 通用推送-重贴标签算法的分析")]),t._v(" "),a("p",[t._v("为了证明通用的推送-重贴标签算法确实会终止，这里给出该算法所执行的操作的次数界。分别对这三类操作求界：重贴标签操作、饱和推送操作、非饱和推送操作。在获得每种操作次数的界后，就可以直接构造一个运行时间为 "),a("code",[t._v("O(|V|^2 |E|)")]),t._v(" 的算法。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.19")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 中的一个预流。那么对于任意溢出结点 x，在"),a("strong",[t._v("残存网络")]),t._v(" Gf 中存在一条从结点 x "),a("strong",[t._v("到源结点")]),t._v(" s 的简单路径。")]),t._v(" "),a("p",[t._v("下面的引理将给出结点的高度的界，该引理的推论则对重贴标签操作的总次数进行了限定。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.20")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，在 G 上执行算法 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 过程中的任意时刻，对于所有结点 u \\in V，均有 "),a("code",[t._v("u.h <= 2|V| - 1")]),t._v("。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("推论 26.21")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，在 G 上执行算法 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 过程中，对"),a("strong",[t._v("每个结点")]),t._v("所执行的"),a("strong",[t._v("重贴标签")]),t._v("操作的次数最多为 "),a("code",[t._v("2|V| - 1")]),t._v(" 次，而"),a("strong",[t._v("所有重贴标签操作")]),t._v("不会超过 "),a("code",[t._v("(2|V| - 1)(|V| - 2) < 2|V|^2")]),t._v(" 次。")]),t._v(" "),a("p",[t._v("引理 26.20 同时也有助于对饱和推送操作的次数进行限定。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.22")]),t._v("（"),a("strong",[t._v("饱和推送")]),t._v("操作次数的上界）：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，在 G 上执行算法 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 过程中，饱和推送操作的次数少于 "),a("code",[t._v("2|V|·|E|")]),t._v("。")]),t._v(" "),a("p",[t._v("下面的引理对通用的推送-重贴标签算法中的非饱和推送操作次数进行了限制。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.23")]),t._v("（"),a("strong",[t._v("非饱和推送")]),t._v("操作次数的上界）：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，在 G 上执行算法 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 过程中，非饱和推送操作的次数少于 "),a("code",[t._v("4|V|^2 (|V| + |E|)")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-3.png",alt:"push-relabel-3"}})]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("定理 26.24")]),t._v("：在任意流网络 G = (V, E) 上执行算法 "),a("code",[t._v("GENERIC_PUSH_RELABEL")]),t._v(" 过程中，基本操作的总次数是 "),a("code",[t._v("O(|V|^2 |E|)")]),t._v("。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("推论 26.25")]),t._v("：对于任意流网络 G = (V, E)，都存在一种通用的推送-重贴标签算法的实现，其运行时间是 "),a("code",[t._v("O(|V|^2 |E|)")]),t._v("。")]),t._v(" "),a("p",[t._v("实现推送-重贴标签算法，往往需要使得每个重贴标签的操作成本为 "),a("code",[t._v("O(|V|)")]),t._v("，而每个推送操作的成本为 O(1)。并且需要设计一个数据结构，使得可以在 O(1) 时间内选出一个合适的操作（以便在当前 while 循环来执行），从而使得整个算法的运行时间为 "),a("code",[t._v("O(|V|^2 |E|)")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"前置重贴标签算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前置重贴标签算法"}},[t._v("#")]),t._v(" 前置重贴标签算法")]),t._v(" "),a("p",[t._v("推送-重贴标签方法允许以任意次序执行基本操作（重贴标签、饱和推送、非饱和推送）。而"),a("strong",[t._v("前置重贴标签算法")]),t._v(" (Relabel-To-Front) 仔细地选择操作的次序，并对网络数据结构进行高效地管理，从而达到 "),a("code",[t._v("O(|V|^3)")]),t._v(" 的时间复杂度。")]),t._v(" "),a("p",[t._v("前置重贴标签算法在执行过程中维持一个网络中结点的链表。算法从头到尾对链表进行扫描，每次选择一个溢出结点 u，然后对所选结点进行“释放”：对所选结点执行推送操作和重贴标签操作，直至该结点 u 的超额流量 u.e 等于 0 为止。")]),t._v(" "),a("p",[t._v("因为每次在算法对一个结点进行重贴标签操作时，都会将该结点移动到链表的首部，故此算法得名为 "),a("strong",[t._v("前置重贴标签算法")]),t._v(" (Relabel-To-Front)。在移动之后，算法会开始一次新的扫描。")]),t._v(" "),a("p",[t._v("前置重贴标签算法的正确性和时间复杂度分析 都依赖于所谓的“"),a("strong",[t._v("许可边")]),t._v("”的概念。许可边是指在残存网络中，流可以经其进行推送的边。")]),t._v(" "),a("h3",{attrs:{id:"许可边和网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#许可边和网络"}},[t._v("#")]),t._v(" 许可边和网络")]),t._v(" "),a("p",[t._v("设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 中的一个预流，h 是一个高度函数。对于边 (u, v)，如果 cf(u, v) > 0 且 h(u) = h(v) + 1，则边 (u, v) 是一条"),a("strong",[t._v("许可边")]),t._v("；否则，边 (u, v) 是一条"),a("strong",[t._v("非许可边")]),t._v("。"),a("strong",[t._v("许可网络")]),t._v("是指图 Gfh = (V, Efh)，其中 Efh 是许可边的集合。")]),t._v(" "),a("p",[t._v("从上述定义可知，许可网络由那些可以在其上推送流的边所构成。下面的引理表明这种网络是一个有向无环图 (Directed Acyclic Graph, DAG)：")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.26")]),t._v("（"),a("strong",[t._v("许可网络是无环的")]),t._v("）：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 中的一个预流，h 是一个高度函数。则许可网络 Gfh = (V, Efh) 是无环的。")]),t._v(" "),a("p",[t._v("下面的两个引理说明推送操作和重贴标签操作是如何改变许可网络的：")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.27")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 中的一个预流，h 是一个高度函数。如果结点 u 是一个溢出结点，且 (u, v) 是一条许可边，则 "),a("code",[t._v("PUSH(u, v)")]),t._v(" 操作适用于结点 u。该操作不会创建任何新的许可边，但有可能导致边 (u, v) 成为非许可边。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.28")]),t._v("：设 G = (V, E) 是一个源结点为 s、汇点为 t 的流网络，并设 f 为 G 中的一个预流，h 是一个高度函数。如果结点 u 是一个溢出结点，且不存在从结点 u 发出的许可边，则 "),a("code",[t._v("RELABEL(u)")]),t._v(" 操作适用于结点 u。此外，在对结点 u 进行重贴标签操作后，将至少存在一条从结点 u 发出的许可边，但不存在进入结点 u 的许可边。")]),t._v(" "),a("h3",{attrs:{id:"邻接链表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#邻接链表"}},[t._v("#")]),t._v(" 邻接链表")]),t._v(" "),a("p",[t._v("在前置重贴标签算法中，将所有的边都组织为“邻接链表”。给定流网络 G = (V, E)，对于结点 u \\in V，其邻接链表 u.N 是结点 u 在图 G 中的邻接结点所构成的一个单链表。因此，如果边 (u, v) \\in E 或者 (v, u) \\in E，则结点 v 将出现在链表 u.N 中。")]),t._v(" "),a("p",[t._v("邻接链表 u.N 包含的结点恰好是那些可能存在残存边 (u, v) 的结点 v。属性 u.N.head 指向的是邻接链表 u.N 中的第一个结点，v.next-neighbor 指向的是在链表 u.N 中位于结点 v 后面的一个结点（即 v 的后继结点）。如果 v 是链表中的最后一个结点，则该指针的值为 nil 空。")]),t._v(" "),a("p",[t._v("前置重贴标签算法以任意次序遍历每个邻接链表，但是一旦定下来此次序，在算法的整个执行过程中就维持不变了。对于每个结点 u，属性 u.current 指向的是 u.N 链表中当前正在考察的结点。在初始状态下，u.curent 被设置为 u.N.head。")]),t._v(" "),a("h3",{attrs:{id:"释放溢出结点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#释放溢出结点"}},[t._v("#")]),t._v(" 释放溢出结点")]),t._v(" "),a("p",[t._v("对于溢出结点 u，如果将其所有多余的流 通过许可边推送到相邻的结点上，则称该结点得到"),a("strong",[t._v("释放")]),t._v("。在释放过程中，需要对结点 u 进行重贴标签操作，这使得从结点 u 发出的某条边成为许可边。下面是释放操作 "),a("code",[t._v("DISCHARGE")]),t._v(" 的伪代码：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("DISCHARGE(u)\n1  while u.e > 0\n2      v = u.current\n3      if v == nil\n4          RELABEL(u)\n5          u.current = u.N.head\n6      elseif cf(u, v) > 0 and u.h == v.h + 1\n7          PUSH(u, v)\n8      else\n9          u.current = v.next-neighbor\n")])])]),a("p",[t._v("算法流程描述如下：")]),t._v(" "),a("ol",[a("li",[t._v("在 1～9 行的 while 循环，只要结点 u 还有正值的超额流量 u.e，该循环就持续执行。每次迭代执行三种操作中的某一种，具体执行哪种操作取决于邻接链表 u.N 中当前结点 v 的情况。")]),t._v(" "),a("li",[t._v("在 2 行，取出 u 的邻接结点中 当前需要考虑的结点 v。")]),t._v(" "),a("li",[t._v("在 3～5 行，分支一：如果结点是 nil 空，则表示运行到了链表 u.N 的尾部了，前面的邻居结点 v 都已考虑过了。此时 u 还有超额流量 u.e > 0，所以需要对 u 执行重贴标签操作，以提升其高度，便于执行 "),a("code",[t._v("PUSH")]),t._v(" 操作来推送 u 中超额的流量。\n"),a("ul",[a("li",[t._v("在 4 行，对结点 u 进行重贴标签操作、提升结点高度。")]),t._v(" "),a("li",[t._v("在 5 行，将结点 u 的当前考虑结点设为 u.N 的首元素。")])])]),t._v(" "),a("li",[t._v("在 6～7 行，分支二：结点 v 不是 nil 空，并且边 (u, v) 是一条许可边，则第 7 行将结点 u 的部分（也可能是全部）超额流量推送到结点 v 上。")]),t._v(" "),a("li",[t._v("在 8～9 行，分支三：结点 v 不是 nil 空，但边 (u, v) 是非许可边，则第 9 行将邻接链表 u.N 中的 u.current 指针指向 v 的后继结点，下轮 while 循环考虑此后继结点。")])]),t._v(" "),a("p",[t._v("另外，注意到，如果针对一个溢出结点 u 来调用 "),a("code",[t._v("DISCHARGE(u)")]),t._v(" 算法，则此过程所执行的最后一个操作必定是对结点 u 所执行的推送操作。因为该算法终止的唯一条件是当 u.e 为 0 时，重贴标签操作 和 将指针 u.current 指向 v 的后继结点的操作 都不会影响 u.e 的取值。")]),t._v(" "),a("p",[t._v("下面图 26-9 描述的是 "),a("code",[t._v("DISCHARGE(u)")]),t._v(" 算法 while 循环的几次执行。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-4.png",alt:"push-relabel-4"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-5.png",alt:"push-relabel-5"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-6.png",alt:"push-relabel-6"}})]),t._v(" "),a("p",[t._v("必须确保，当 "),a("code",[t._v("DISCHARGE(u)")]),t._v(" 算法调用 "),a("code",[t._v("PUSH")]),t._v(" 或 "),a("code",[t._v("RELABEL")]),t._v(" 操作时，该操作确实是当时适用的操作。下面的引理将证明这个性质。")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("引理 26.29")]),t._v("：如果 "),a("code",[t._v("DISCHARGE(u)")]),t._v(" 算法在第 7 行调用 "),a("code",[t._v("PUSH(u, v)")]),t._v(" 操作，则此时推送操作适用于边 (u, v)。如果 "),a("code",[t._v("DISCHARGE(u)")]),t._v(" 算法在第 4 行调用 "),a("code",[t._v("RELABEL(u)")]),t._v(" 操作，则此时重贴标签操作适用于结点 u。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-7.png",alt:"push-relabel-7"}})]),t._v(" "),a("h3",{attrs:{id:"前置重贴标签算法实现"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前置重贴标签算法实现"}},[t._v("#")]),t._v(" 前置重贴标签算法实现")]),t._v(" "),a("p",[t._v("在前置重贴标签算法中，维持一个链表 L，该链表由 V - {s, t} 中的所有结点构成。这里的关键性质是：链表 L 中的结点均按照"),a("strong",[t._v("许可网络")]),t._v("的"),a("strong",[t._v("拓扑排序")]),t._v("次序存放。（由前面的引理 26.26 可知，许可网络是一个有向无环图 DAG）")]),t._v(" "),a("p",[t._v("在下面的伪代码中，假定针对每个结点 u，邻接链表 u.N 都已经被创立。该算法同时还假定 u.next 指针指向链表 L 中紧随结点 u 的结点（结点 u 的后继结点），并且如果结点 u 是链表的最后一个结点，则 u.next = nil。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("RELABEL_TO_FRONT(G, s, t)\n1  INITIALIZE_PREFLOW(G, s)\n2  L = G.V - {s, t}, in any order\n3  for each vertex u \\in G.V - {s, t}\n4      u.current = u.N.head\n5  u = L.head\n6  while u != nil\n7      old_height = u.h\n8      DISCHARGE(u)\n9      if u.h > old_height\n10         move u to the front of list L\n11         u = u.next\n")])])]),a("p",[t._v("算法流程描述如下：")]),t._v(" "),a("ol",[a("li",[t._v("在 1 行，对网络的预流和结点高度进行初始化。此初始化过程调用与 通用推送-重贴标签算法用到的初始化过程 相同。")]),t._v(" "),a("li",[t._v("在 2 行，对链表 L 进行初始化，其中包含的是所有可能出现潜在溢出的结点，而结点之间的次序可以是任意的。\n"),a("ul",[a("li",[t._v("因为此时没有许可边，所以任意次序都是 Gfh 的一个拓扑排序，此后的循环过程中也会保持链表 L 中结点的次序为拓扑排序。")])])]),t._v(" "),a("li",[t._v("在 3～4 行，对每个结点 u 的 current 指针进行初始化，使该指针指向 u 的邻接链表 u.N 的首元素。")]),t._v(" "),a("li",[t._v("在 5 行，获取链表首元素 u，从 u 开始考察处理。")]),t._v(" "),a("li",[t._v("在 6～11 行的 while 循环中，对链表 L 进行遍历并逐个释放结点。\n"),a("ul",[a("li",[t._v("在 7 行，记录 "),a("code",[t._v("DISCHARGE")]),t._v(" 释放操作前 u 的高度。如果结点 u 在释放过程中执行了重贴标签操作，其高度会提升，从而方便第 9 行的判断。")]),t._v(" "),a("li",[t._v("在 8 行，对结点 u 进行释放操作。")]),t._v(" "),a("li",[t._v("在 9 行，通过高度变化来判断 u 在释放过程中 是否执行过重贴标签操作。")]),t._v(" "),a("li",[t._v("在 10 行，如果 u 执行过重贴标签操作，则将结点 u 移至链表 L 首部。")]),t._v(" "),a("li",[t._v("在 11 行，以链表 L 中结点 u（此时已被移动至 L 首部）的后继结点作为下一次 while 循环处理的结点。")])])])]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-8.png",alt:"push-relabel-8"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-9.png",alt:"push-relabel-9"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-10.png",alt:"push-relabel-10"}})]),t._v(" "),a("h3",{attrs:{id:"前置重贴标签算法分析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前置重贴标签算法分析"}},[t._v("#")]),t._v(" 前置重贴标签算法分析")]),t._v(" "),a("p",[t._v("可以证明，前置重贴标签算法在"),a("strong",[t._v("任何流网络")]),t._v(" G = (V, E) 上的运行时间为 "),a("code",[t._v("O(|V|^3)")]),t._v("。因为该算法是通用的推送-重贴标签算法的一种实现。")]),t._v(" "),a("p",[t._v("前面的推论 26.21 说明每个结点的重贴标签操作次数不超过 "),a("code",[t._v("O(|V|)")]),t._v("，因此所有结点的重贴标签操作总次数不超过 "),a("code",[t._v("O(|V|^2)")]),t._v("。而前面的引理 26.22 说明饱和推送操作的总次数为 "),a("code",[t._v("O(|V|·|E|)")]),t._v("。另外，《CLRS》联系 26.4-3 表明：通用的推送-重贴标签算法只用了总共 "),a("code",[t._v("O(|V|·|E|)")]),t._v(" 的时间来执行所有 "),a("code",[t._v("O(|V|^2)")]),t._v(" 个重贴标签操作。于是有如下定理：")]),t._v(" "),a("p",[t._v("《CLRS》"),a("strong",[t._v("定理 26.30")]),t._v("：前置重贴标签算法在任何流网络 G = (V, E) 上的运行时间为 "),a("code",[t._v("O(|V|^3)")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-11.png",alt:"push-relabel-11"}})]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/graph_theory/max_flow/push-relabel-12.png",alt:"push-relabel-12"}})]),t._v(" "),a("h2",{attrs:{id:"python-代码范例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-代码范例"}},[t._v("#")]),t._v(" Python 代码范例")]),t._v(" "),a("p",[t._v("Python 环境：Python 3.7")]),t._v(" "),a("h3",{attrs:{id:"relabel-to-front-前置重贴标签-最大流算法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#relabel-to-front-前置重贴标签-最大流算法"}},[t._v("#")]),t._v(" Relabel-To-Front 前置重贴标签-最大流算法")]),t._v(" "),a("ul",[a("li",[t._v("Ford-Fulkerson 方法\n"),a("ul",[a("li",[t._v("Ford-Fulkerson 算法 O(V |f*|)")]),t._v(" "),a("li",[t._v("Edmonds-Karp 算法 O(V E^2)")])])]),t._v(" "),a("li",[t._v("Push-Relabel 推送-重贴标签方法\n"),a("ul",[a("li",[t._v("Push-Relabel 通用的推送-重贴标签算法 O(V^2 E)")]),t._v(" "),a("li",[t._v("Relabel-To-Front 前置重贴标签算法 O(V^3)")])])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#!/usr/bin/env python")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -*- coding:utf-8 -*-")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""=================================================\n@Project : algorithm/graph_theory/max_flow_matching\n@File    : push-relabel.py\n@Author  : YuweiYin\n@Date    : 2020-06-04\n=================================================="""')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n最大流 Max-Flow\n\n- Push-Relabel 推送-重贴标签方法\n    - Push-Relabel 通用的推送-重贴标签算法 O(V^2 E)\n    - Relabel-To-Front 前置重贴标签算法 O(V^3)\n\n参考资料：\nIntroduction to Algorithm (aka CLRS) Third Edition - Chapter 26\n"""')]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边结构体，表达边的信息，可随任务自定义 (增添其它值元素 val 对象)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Edge")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 构造方法")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" from_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" capacity"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" from_v  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边的起始顶点(关键字/序号)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" to_v      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边的终止顶点(关键字/序号)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" weight  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (用于最短路)边的权重值 (默认值为 1，如果全部边的权重都相同，那图 G 就是无权图)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_directed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" is_directed  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# True 则表明此边是有向边，False 为无向边")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对无向边而言，起始顶点和终止顶点可以互换")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''下面是用于 Max-Flow 的属性'''")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("capacity "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" capacity  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此边的最大容量")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("             "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此边最大流的流量，初始为 0，取值范围 0 <= flow <= capacity")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 运行过程中的边流量存储于矩阵中，这里的 self.flow 仅存储最终的本条边的流量")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 类序列化输出方法")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__str__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'->'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" \\\n               "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t capacity:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("capacity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t flow:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" \\\n               "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t weight:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("weight"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\t is_directed:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_directed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用于邻接表的顶点结构体")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里是用散列表 (而不是用链表) 来表达某顶点的所有邻接顶点")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("VertexList")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 构造方法")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pre_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" next_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" height"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exceed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" key            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 本顶点的关键字 key (通常为顶点序号、唯一标志符)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("val "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" val            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 本顶点的值元素 val (可自定义为任意对象，为结点附带的信息)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 本顶点的邻居字典，key 为邻居的关键字，value 为 Edge 边结构体")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果是有向图，本结点为关联边的出发点 from_v，其邻居关联边的终止点 to_v")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''下面是用于 Max-Flow 的属性'''")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pre_v        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此结点在单链表 L 中的前驱结点")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" next_v      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此结点在单链表 L 中的后继结点 (L 中的结点会保持拓扑排序次序)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" height      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此结点的高度(标签)。取值不低于 0")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" exceed      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此结点的超额流量。取值不低于 0")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 类序列化输出方法")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__str__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'key:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\theight:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\texceed:'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 增添本顶点的邻居 neighbor，以字典结构存储")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 注意：如果不允许图有自环/自圈，那么在增添邻居/边 的时候要禁止增添 self.neighbor[self.key] 项。这里暂不限制")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add_neighbor")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 neighbor 字典里已有此 key，则会覆盖。起到了更新边信息的作用")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("weight"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("is_directed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以 Edge 边结构体来增添本顶点的邻居 neighbor")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("add_edge")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检查输入 edge 的合法性")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 edge 是有向边，那么本结点需要是 edge 的出发点 from_v")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_directed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 edge 是无向边，那么本结点需要是 edge 的出发点 from_v 或结束点 to_v 之一")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先把 from_v 和 to_v 交换")]),t._v("\n                    edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v\n                    edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key\n                    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回本顶点的所有邻接顶点(的关键字/序号) 数组")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_connections")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回本顶点到邻居 neighbor 的 Edge 边结构体")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_weight")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" neighbor "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 邻接表+邻接矩阵的图结构")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输入顶点结构体列表、边结构体列表")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AdjacencyListMatrix")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# self.inf = 0x3f3f3f3f        # 初始各边的权重值均为 inf 无穷")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 经最大流算法后计算出的最大流值")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edges "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edges           "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 存储输入的边列表")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2e_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 由(起始,终止)顶点的关键字/唯一标志符映射到边数组下标")]),t._v("\n\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" vertices     "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 存储输入的顶点列表 (可以从下标映射到顶点)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("v2index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 由顶点映射到其下标 (既是邻接矩阵的行/列下标，也是 vertices 列表的下标)")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 由顶点的关键字/唯一标志符映射到顶点数组下标")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" vertex "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("v2index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("vertex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" index\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("vertex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" index\n\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 本图的顶点字典, key 为顶点的序号，val 为顶点结构体")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" vertex "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("vertex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" vertex\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 构建残存网络 Gf(二维方阵)，adj[x][y] 的值为边 (x, y) 的当前流量，而不是边权重")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 残存网络 Gf 可以有反平行边。如果 adj[x][y] 为 0 表示没有此边")]),t._v("\n        v_num "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 顶点数目")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" v_num "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" _ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v_num"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 若 edges 合法，则进行边初始化处理")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" edge "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 断言最大流算法里都是有向边")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_directed\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 给邻接链表增加边")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果是有向边")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_directed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" from_v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果是无向边")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v\n                    to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" from_v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" to_v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 给邻接矩阵 (残存网络 Gf) 增加边")]),t._v("\n                from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边起点的关键字 key")]),t._v("\n                to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边终点的关键字 key")]),t._v("\n                capacity "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("capacity  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边的容量")]),t._v("\n                self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2e_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" index\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" from_v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" to_v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将顶点关键字 key 转为下标 index，然后初始化 adj[from][to] 为边的最大容量")]),t._v("\n                    from_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    to_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" from_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" v_num "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" to_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" v_num\n                    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" capacity\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 判断 key 号为 _key 的顶点是否位于顶点列表中")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__contains__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" _key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 类迭代器方法")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__iter__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("iter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取图中 key 号为 _key 的顶点，如果没有此顶点则返回 None")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_vertex")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" _key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" _key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("adj_l"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 邻接表 - 图转置")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("graph_transposition")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" edge "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 其实如果是无向边，无需处理，但这里还是转了")]),t._v("\n            temp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v\n            edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v\n            edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" temp\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出邻接矩阵 (残存网络 Gf)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("print_matrix_info")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" row "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最大流算法")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Push-Relabel 通用的推送-重贴标签算法 O(V^2 E)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Relabel-To-Front 前置重贴标签算法 O(V^3)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("PushRelabel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x3f3f3f3f")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 所有结点的 distance 初始化为 inf")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 初始化预流")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度：O(V + E)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 该初始化过程 将从源结点 s 发出的所有边都充满流（即理想上 最大流的最大可能取值，也即是切割 ({s}, V-{s}) 的容量），")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 而其它边上都没有流。对于每个与源结点 s 相邻的结点 v，一开始其超额流 v.e = c(s, v)，")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因为流入 v 的流量是 c(s, v)，而流出 v 的流量为 0。并且将 s.e 初始化为所有这些容量之和的相反数。")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 至于高度(标签)，一开始仅有源结点 s 高度为 `|V|`，其余结点的高度均为 0")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@staticmethod")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("initialize_preflow")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 首先确认输入的合法性，并将输入的源结点关键字 转为结点结构体")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AdjacencyListMatrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" source_v_key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index\n        source_v_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        source_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("source_v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 一开始仅有源结点 s 高度为 `|V|`，其余结点的高度均为 0")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n            v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n        source_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 让从源结点 s 发出的所有边都充满流，而其它边上都没有流")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 即理想上 最大流的最大可能取值，也即是切割 ({s}, V-{s}) 的容量")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" edge "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" edge "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" source_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("neighbor"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 v 的关键字获取顶点结构体")]),t._v("\n            to_v_key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_v\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" to_v_key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index\n            to_v_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            to_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置残存网络的边")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# - 若 u == s，则 (u, v).f = c(u, v) 在本实现中意味着残存网络中 cf(u, v) = 0 而 cf(v, u) = c(u, v)")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# - 若 u != s，则 (u, v).f = 0 在本实现中意味着残存网络中 cf(v, u) = c(u, v) 而 cf(v, u) = 0")]),t._v("\n            adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("source_v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n            adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("source_v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("capacity\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置邻居结点 v 的超额流量")]),t._v("\n            to_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("capacity\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 减少源结点的超额流量")]),t._v("\n            source_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-=")]),t._v(" edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("capacity\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 预流推送操作：把 u 的超额流量 u.e 推送给 v")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度：O(1)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@staticmethod")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("push_flow")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AdjacencyListMatrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 需保证此时 u 的超额流量 u.e 大于零，且 u 的高度 u.h 比 v 的高度 v.h 高 1")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 且残存网络中残存边 (u, v) 的残存容量大于 0，即 cf(u, v) > 0")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index\n        u_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        v_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        cf_uv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边 (u, v) 的残存容量")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" cf_uv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 满足推送的条件")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 计算 u 的超额量 与 边 (u, v) 的残存容量 二者的较小者，作为推送的流量")]),t._v("\n            delta_flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("min")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cf_uv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 推送后，改变残存网络的相应边的流量")]),t._v("\n            adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-=")]),t._v(" delta_flow  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 正向边容量 cf 减少")]),t._v("\n            adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" delta_flow  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 反向边容量 cf 增加")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 推送后，改变结点 u 和 v 的超额流量")]),t._v("\n            u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-=")]),t._v(" delta_flow  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u.e 减少")]),t._v("\n            v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" delta_flow  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# v.e 增加")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 不满足推送的条件")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 重贴标签操作：把结点 u 的标签(高度)提升到 能够把超额的流量推送给某个邻居结点")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度：O(V)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@staticmethod")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("relabel")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AdjacencyListMatrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 需保证此时 u 的超额流量 u.e 大于零，考察 u 的各个邻居结点，选择某个满足如下性质的"最矮的"结点 v')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 残存网络中残存边 (u, v) 的残存容量大于 0，即 cf(u, v) > 0")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            min_h "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x3f3f3f3f")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index\n            u_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 从残存网络矩阵中逐结点考虑")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" capacity "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" capacity "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" min_h"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        min_h "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里断言一定存在某个可以推送流的边 (u, v)")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" min_h "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height\n            u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" min_h "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u 的流量没有超额，不满足重贴标签的条件")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 释放溢出结点：把结点 u 的超额的流量推送给某个邻居结点，直至 u 不再具有超额流量，即 u.e == 0")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度：O(V)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("discharge")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AdjacencyListMatrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 需保证此时 u 的超额流量 u.e 大于零，考察 u 的各个邻居结点，选择某个满足如下性质的"最矮的"结点 v')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 残存网络中残存边 (u, v) 的残存容量大于 0，即 cf(u, v) > 0")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取 u 的邻居关键字列表，固定此顺序来试图将 u 的超额流量推送给各邻居")]),t._v("\n            n_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里考察所有可能邻居，而不仅是邻接的结点")]),t._v("\n            list_len "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            cur_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当前考察的邻居下标")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前邻居的 index 越界，则需对结点 u 重贴标签、提升高度")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" cur_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" list_len"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    cur_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 重新从头开始考察 u 的邻居")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 index 不越界，则考察当前邻居")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取邻居结点结构体")]),t._v("\n                    cur_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" n_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("cur_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cur_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 考察此边是否为许可边")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index\n                    u_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cf_uv = adj_lm.graph_f[u_index][cur_v_index]  # 边 (u, v) 的残存容量")]),t._v("\n                    cf_uv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("u_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("cur_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 边 (u, v) 的残存容量")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" cf_uv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" cur_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前边是许可边，则把 u 的一定量的超额流推送给邻居结点 v")]),t._v("\n                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 每次 discharge 中，非饱和推送至多为 1 次")]),t._v("\n                        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("push_flow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cur_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 否则当前边是非许可边，则进入下个 while 循环，考察下一个邻居结点")]),t._v("\n                        cur_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 断言此时结点 u 的超额流量为 0")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exceed "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 使用 Relabel-To-Front 前置重贴标签算法 计算流网络 adj_m 的最大流")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度：O(V^3)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("do_relabel_to_front")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" terminal_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 首先确认输入的合法性，并将输入的源结点和汇点关键字 转为结点结构体")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AdjacencyListMatrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" source_v_key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" terminal_v_key "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index\n        source_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        terminal_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2v_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("terminal_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("terminal_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. 对网络的预流和结点高度进行初始化。")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("initialize_preflow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. 对链表 L 进行初始化，其中包含的是所有可能出现潜在溢出的结点，而结点之间的次序可以是任意的")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    因为此时没有许可边，所以任意次序都是 Gfh 的一个拓扑排序，此后的循环过程中也会保持链表 L 中结点的次序为拓扑排序")]),t._v("\n        _list_head "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'__list_head__'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 链表头结点。注意此 key 不能与实际的结点 key 重复")]),t._v("\n        ptr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" _list_head\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将除源结点 s 和汇点 t 的结点都链接到双向链表中")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" source_v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" terminal_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr\n                ptr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n                ptr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 对每个结点 u 的 current 指针进行初始化，使该指针指向 u 的邻接链表 u.N 的首元素")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#    在本实现中略去此步骤")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 4. 获取链表首元素 u，从 u 开始考察处理")]),t._v("\n        u "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" _list_head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 5. 在 while 循环中，对链表 L 进行遍历并逐个释放结点")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" u "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 记录释放操作前 u 的高度")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果结点 u 在释放过程中执行了重贴标签操作，其高度会提升，从而方便后面的判断")]),t._v("\n            old_height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height\n\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对结点 u 进行释放操作")]),t._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("discharge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 通过高度变化来判断 u 在释放过程中 是否执行过重贴标签操作")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("height "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" old_height"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 u 执行过重贴标签操作，则将结点 u 移至链表 L 首部")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先判断 u 是否已在首部，如果是，则不改变链表结构")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" _list_head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" _list_head "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先让 u 的前驱和后继结点相连")]),t._v("\n                    u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 然后把 u 插入到首部")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_list_head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    _list_head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u\n                    u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" _list_head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v\n                    u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pre_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" _list_head\n                    _list_head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u\n\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以链表 L 中结点 u 的后继结点作为下一次 while 循环处理的结点")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果结点 u 在释放过程中执行过重贴标签操作，那么此时 u 已被移动至 L 首部")]),t._v("\n            u "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_v\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 3. 最后，当 while 循环结束时，此时流 flow 就是最大流")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在本实现中，adj_lm.graph_f 矩阵保存的就是残存网络 Gf 中各个边的流量，最终将实际的流量赋予各个结点的 flow 属性")]),t._v("\n        adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" from_index "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" to_index "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                from_node "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                to_node "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("to_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果此边是原图中的边，则赋予该边 flow 属性，表示最大流的流量")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2e_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    edge_index "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key2e_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_node"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    edge "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("edge_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                    edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("         "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 赋予此边流量属性 flow")]),t._v("\n                    adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_flow "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+=")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("from_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("to_index"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 增长图的最大流量值")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 构造图同《CLRS》图 26-10 的(含边容量的)有向图用于计算最大流")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用于构造邻接矩阵的顶点的 key/val 信息列表")]),t._v("\n    matrix_vertices_info "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'s'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'x'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'y'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'z'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("400")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 有向边的 from/to/c/is_directed 信息列表")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# is_directed 为 True 表示此边为有向边，否则为无向边")]),t._v("\n    di_edges_info "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'s'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'x'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'s'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'y'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'x'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'y'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'x'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'y'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'z'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'z'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'x'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'z'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据前述列表信息构造结点列表")]),t._v("\n    matrix_vertices "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    di_edges "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" matrix_vertices_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        matrix_vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("VertexList"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" e "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" di_edges_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        di_edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Edge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("from_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" to_v"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" capacity"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is_directed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建有向图的邻接表/邻接矩阵")]),t._v("\n    adj_lm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AdjacencyListMatrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("matrix_vertices"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" di_edges"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 执行 O(V^3) Push-Relabel 最大流算法 (Relabel-To-Front)")]),t._v("\n    source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" terminal_v_key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'s'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'t'")]),t._v("\n    push_relabel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PushRelabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    start "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("process_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    push_relabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("do_relabel_to_front"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" source_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" terminal_v_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    end "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("process_time"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出结果 & 运行时间")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# max_flow: 24")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [0, 0, 6, 0, 0]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [12, 0, 5, 0, 4]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [8, 0, 0, 0, 0]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [0, 7, 8, 0, 2]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [0, 12, 0, 8, 0]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\nmax_flow:'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_flow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    adj_lm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print_matrix_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Running Time: %.5f ms'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"__main__"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    sys"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("h2",{attrs:{id:"参考资料"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),a("ul",[a("li",[t._v("Introduction to Algorithm (aka CLRS) Third Edition - Chapter 26")])])])}),[],!1,null,null,null);s.default=e.exports}}]);