(window.webpackJsonp=window.webpackJsonp||[]).push([[15],{294:function(t,e,a){"use strict";a.r(e);var r=a(28),s=Object(r.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"algorithm-sort-hashing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#algorithm-sort-hashing"}},[t._v("#")]),t._v(" Algorithm - Sort - Hashing")]),t._v(" "),a("p",[t._v("Create Date: 2020.05.11")]),t._v(" "),a("p",[t._v("Last Update Date: 2020.05.12")]),t._v(" "),a("p",[t._v("By "),a("a",{attrs:{href:"https://yuweiyin.github.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("YuweiYin"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),a("h3",{attrs:{id:"哈希散列-hashing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#哈希散列-hashing"}},[t._v("#")]),t._v(" 哈希散列 Hashing")]),t._v(" "),a("p",[t._v("许多应用都需要一种动态集合结构，它至少要支持 Insert、Search 和 Delete 这三种"),a("strong",[t._v("字典操作")]),t._v("。例如，用于程序语言编译的编译器维护了一个符号表，其中元素的关键字为任意字符串，它与程序中的标识符相对应。")]),t._v(" "),a("p",[a("strong",[t._v("散列表")]),t._v(" (Hash Table) 是实现字典操作的一种有效数据结构。尽管在最坏情况下，散列表中查找一个元素的时间与链表中查找的时间相同，达到了 "),a("code",[t._v("\\Theta(n)")]),t._v("。然而在"),a("strong",[t._v("实际应用")]),t._v("中，散列表"),a("strong",[t._v("查找的性能是极好的")]),t._v("。在一些"),a("strong",[t._v("合理的假设")]),t._v("下，在散列表中查找一个元素的平均时间是 O(1)。")]),t._v(" "),a("p",[t._v("散列表是普通数组概念的推广。由于对普通数组可以直接寻址，使得能在 O(1) 时间内访问数组中的任一位置。")]),t._v(" "),a("p",[t._v("散列是一种极其有效和实用的技术：基本的字典操作平均只需要 O(1) 的时间。")]),t._v(" "),a("p",[t._v("Python 语言中的内建 dict 字典类型即为一种哈希表。几乎所有的现代高级编程语言中均有内建的字典类型。")]),t._v(" "),a("h2",{attrs:{id:"直接寻址-direct-access-table"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#直接寻址-direct-access-table"}},[t._v("#")]),t._v(" 直接寻址 Direct-Access Table")]),t._v(" "),a("p",[t._v("当关键字的全域 U 比较小时，直接寻址是一种简单而有效的技术。假设某应用要用到一个动态集合，其中每个元素都是取自于全域 "),a("code",[t._v("U={0, 1, ..., m-1}")]),t._v(" 中的一个关键字 key，这里 m 不是一个很大的数。另外，假设没有两个元素具有相同的关键字。")]),t._v(" "),a("p",[t._v("为表示动态集合，用一个数组（"),a("strong",[t._v("直接寻址表")]),t._v(" direct-address table），记为 "),a("code",[t._v("T[0..m-1]")]),t._v("。其中每个位置，或称为 "),a("strong",[t._v("槽")]),t._v(" slot，对应全域 U 中的一个关键字 key。下图描绘了此方法，槽 k 指向集合中一个关键字为 k 的元素。如果该集合中没有关键字为 k 的元素，则 "),a("code",[t._v("T[k]=NIL")]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/data_structure/hashing-1.png",alt:"hashing-1"}})]),t._v(" "),a("p",[t._v("如果存储空间允许，可以提供一个数组，为每个可能的关键字保留一个位置，以利用直接寻址技术的优势。")]),t._v(" "),a("p",[t._v("在直接寻址表中，实现字典操作很简单：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\n")])])]),a("p",[t._v("上述每一个操作都只需要 O(1) 的时间。")]),t._v(" "),a("p",[t._v("对于某些应用，直接寻址表本身就可以存放动态集合中的元素。即，并"),a("strong",[t._v("不")]),t._v("把每个元素的关键字及其附带的卫星数据都放在直接寻址表外部的一个对象中，再由表中某个槽的指针指向该对象。而是直接把该对象存放在直接寻址表的槽中，从而节省了空间。")]),t._v(" "),a("p",[t._v("使用对象内的一个特殊关键字来表明该槽为空槽即可。而且，通常可不必存储该对象的关键字属性，因为如果知道一个对象在表中的下标，就可以得到它的关键字（因为二者之间是双射）。然而，如果不存储关键字，我们就必须要有某种方法来确定某个槽是否为空槽。")]),t._v(" "),a("p",[a("strong",[t._v("位向量")]),t._v(" (bit vector) 是一个仅包含 0 和 1 的数组。长度为 m 的位向量所占的空间要比包含 m 个指针的数组少得多，因此可以利用一个位向量来表示一个包含不同元素（无附带的卫星数据）的动态集合，在其上的字典操作的运行时间为 O(1)。")]),t._v(" "),a("p",[t._v("如果想要在一个"),a("strong",[t._v("非常大")]),t._v("的数组上，通过直接寻址的方式实现一个字典，对整个数组进行初始化是不太实际的。但是可以利用一个附加数组，其处理方式类似于栈，其大小等于实际存储在字典中的关键字数目，以辅助确定大数组中某个给定的项是否有效。从而也能达到每个操作（初始化、搜索、插入、删除）的时间为 O(1)，并且每个存储对象占用 O(1) 的空间。")]),t._v(" "),a("p",[t._v("上述操作常被称为 预哈希 Pre-Hashing，将原始的 key（可以不是整数，Python 中的原始 key 即为字符串）映射成与输入量等长（或者是 O(n) 量级，n 为实际要存储的对象数目）的整数（常为自然数）集合 A，然后对 A 做直接寻址哈希。而 Pre-Hashing 要保证没有冲突，即此映射必须为"),a("strong",[t._v("单射")]),t._v("。也有可能为双射，不过关键是单射，而且一般而言 哈希表长度 m 都会大于 n，只需保证 m=O(n)，则直接寻址哈希表效率为 O(1)。")]),t._v(" "),a("p",[t._v("在 Python 中预哈希操作可以通过重载 "),a("code",[t._v("__hash__")]),t._v(" 函数来自定义，其默认映射方式是调用 id 函数，取对象的物理地址来作为 Pre-Hashing 的结果。")]),t._v(" "),a("ul",[a("li",[a("p",[a("strong",[t._v("注意")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("Pre-Hashing 的一定要是双射，只要 "),a("code",[t._v("__eq__")]),t._v(" 函数（也可以自定义）认为两个原始 key 是相同的，那么其 "),a("code",[t._v("__hash__")]),t._v(" 函数的结果必须相同。")]),t._v(" "),a("li",[t._v("另外，被用于作为原始 key 的对象需要是 immutable 不可变对象（比如 str、int、tuple 对象），而不是 mutable 可变对象（比如 list 对象）。")]),t._v(" "),a("li",[t._v("对于原始 key 是自定义类型的对象，需要同时实现 "),a("code",[t._v("__eq__")]),t._v(" 和 "),a("code",[t._v("__hash__")]),t._v(" 函数，才能正常使用 hash 操作。（当然，同时要保证该 key 对象是不可变类型）")]),t._v(" "),a("li",[t._v("Python 的 dict 字典，对于相同 key、不同 value 的赋值，会采用 overwrite 覆盖机制，只记住最后一次携带的 value。Python dict 的简易使用方式可以"),a("a",{attrs:{href:"https://www.runoob.com/python/python-dictionary.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("参考在线教程"),a("OutboundLink")],1),t._v("。")])])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://docs.python.org/3.7/library/functions.html#hash",target:"_blank",rel:"noopener noreferrer"}},[t._v("Python 3.7 hash"),a("OutboundLink")],1)]),t._v(" "),a("ul",[a("li",[t._v("Return the hash value of the object (if it has one). "),a("strong",[t._v("Hash values are integers")]),t._v(". They are used to quickly compare dictionary keys during a dictionary lookup. Numeric values that compare equal have the same hash value (even if they are of different types, as is the case for 1 and 1.0).")]),t._v(" "),a("li",[a("strong",[t._v("Note")]),t._v(": For objects with custom "),a("code",[t._v("__hash__()")]),t._v(" methods, note that "),a("code",[t._v("hash()")]),t._v(" "),a("strong",[t._v("truncates the return value")]),t._v(" "),a("em",[t._v("based on the bit width")]),t._v(" of the host machine. See "),a("code",[t._v("__hash__()")]),t._v(" for details.")])])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://docs.python.org/3.7/reference/datamodel.html#object.__hash__",target:"_blank",rel:"noopener noreferrer"}},[t._v("Python 3.7 __hash__"),a("OutboundLink")],1)]),t._v(" "),a("ul",[a("li",[t._v("Called by built-in function "),a("code",[t._v("hash()")]),t._v(" and for operations on members of hashed collections including "),a("strong",[t._v("set")]),t._v(", "),a("strong",[t._v("frozenset")]),t._v(", and "),a("strong",[t._v("dict")]),t._v(". "),a("code",[t._v("__hash__()")]),t._v(" should "),a("strong",[t._v("return an integer")]),t._v(". The "),a("strong",[t._v("only required property")]),t._v(" is that "),a("em",[t._v("objects which compare equal have the same hash value")]),t._v(";")]),t._v(" "),a("li",[t._v("it is advised to mix together the hash values of the components of the object that also play a part in comparison of objects by packing them into a tuple and hashing the tuple. Example:")]),t._v(" "),a("li",[a("code",[t._v("def __hash__(self): return hash((self.name, self.nick, self.color))")])]),t._v(" "),a("li",[a("strong",[t._v("Note")]),t._v(": "),a("code",[t._v("hash()")]),t._v(" truncates the value returned from an object’s custom "),a("code",[t._v("__hash__()")]),t._v(" method to the size of a "),a("code",[t._v("Py_ssize_t")]),t._v(". This is typically 8 bytes on 64-bit builds and 4 bytes on 32-bit builds. If an object’s "),a("code",[t._v("__hash__()")]),t._v(" must interoperate on builds of different bit sizes, be sure to check the width on all supported builds. An easy way to do this is with "),a("code",[t._v('python -c "import sys; print(sys.hash_info.width)"')]),t._v(".")]),t._v(" "),a("li",[a("strong",[t._v("Note")]),t._v(": By default, the "),a("code",[t._v("__hash__()")]),t._v(" values of "),a("strong",[t._v("str, bytes and datetime")]),t._v(" objects are “salted” with an "),a("strong",[t._v("unpredictable random value")]),t._v(". Although they "),a("em",[t._v("remain constant within an individual Python process")]),t._v(", they are "),a("strong",[t._v("not predictable")]),t._v(" between repeated invocations of Python.")])])])]),t._v(" "),a("h2",{attrs:{id:"散列表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#散列表"}},[t._v("#")]),t._v(" 散列表")]),t._v(" "),a("p",[t._v("直接寻址技术的缺点是非常明显的：如果全域 U 很大，则在一台标准的计算机可用内存容量中，要存储大小为 "),a("code",[t._v("|U|")]),t._v(" 的一张表 T 也许不太实际，甚至是无法做到的。另外，实际存储的关键字集合 K 相对于 U 来说可能很小，使得分配给 T 的大部分空间都将被浪费掉。")]),t._v(" "),a("p",[t._v("当实际存储的关键字数目 K 比全部可能的关键字总数 U 要小许多时，采用散列表就能成为直接数组寻址的一种有效替代。因为散列表使用一个长度与实际存储的关键字数目成比例的数组来存储，能将散列表的存储需求降至 "),a("code",[t._v("\\Theta (|K|)")]),t._v("，同时散列表中查找一个元素的优势仍然得到保持，平均只需要 O(1) 的时间。")]),t._v(" "),a("p",[t._v("在直接寻址方式下，具有关键字 k 的元素被存放在槽 k 中。在散列表中，不是直接把关键字作为数组的下标，而是根据关键字（利用"),a("strong",[t._v("散列函数")]),t._v(" hash function）计算出相应的槽下标 h(k)。哈希函数 h 将关键字 k 的全域 U 映射到散列表 "),a("code",[t._v("T[0..m-1]")]),t._v(" 的各槽位上，而 m 一般远小于 "),a("code",[t._v("|U|")]),t._v("。可以说一个具有关键字 k 的元素被 "),a("strong",[t._v("散列")]),t._v(" 到槽 h(k) 上，也可以说 h(k) 是关键字 k 的 "),a("em",[a("strong",[t._v("散列值")])]),t._v("。")]),t._v(" "),a("p",[a("img",{attrs:{src:"/img/info_technology/algorithm/data_structure/hashing-2.png",alt:"hashing-2"}})]),t._v(" "),a("h2",{attrs:{id:"解决冲突-链接法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解决冲突-链接法"}},[t._v("#")]),t._v(" 解决冲突 - 链接法")]),t._v(" "),a("p",[t._v("所谓冲突，就是指多个关键字映射到散列表的同一个下标。即 h(k1) = h(k2)，其中 k1 != k2。")]),t._v(" "),a("p",[t._v("散列表解决 "),a("strong",[t._v("碰撞/冲突")]),t._v(" (collision) 的最简单方式就是 "),a("strong",[t._v("链接")]),t._v(" (chaining) 方法。链接法与 "),a("strong",[a("a",{attrs:{href:"../sort/linear-time-sort"}},[t._v("桶排序")])]),t._v(" (Bucket Sort) 类似，散列表中的一个槽就类似于桶排序中的一个桶。")]),t._v(" "),a("p",[t._v("冲突时，将相同 key 的元素链接到同一个单链表中。")]),t._v(" "),a("p",[t._v("最坏的情况，就是所有元素都映射到哈希表的同一位置，从而形成一个特别长的单链表，搜索性能退化到了 O(n)。")]),t._v(" "),a("p",[t._v("桶排序假设输入是接近"),a("strong",[t._v("均匀分布")]),t._v("的，从而能达到很好的效果。对哈希表而言，也希望输入的分布尽量时均匀分布，但这种假设往往只是一种被动的 hope（Simple Uniform Hashing）。所以一般会主动地通过在 Pre-Hashing 操作中加入"),a("strong",[t._v("随机因子")]),t._v("，迫使映射到哈希表的下标分布尽量均匀，从而提升哈希表的性能。")]),t._v(" "),a("p",[a("strong",[t._v("注意")]),t._v("：以 Python 为例，会使用名为 PYTHONHASHSEED 的值来为 str, bytes and datetime objects 设置随机化种子，并且在使用了之后就固定住（一个原始 key 一个 PYTHONHASHSEED）。这样即为哈希函数的结果提供了随机性（从而让映射成的哈希表下标接近均匀分布），也能够保证相同的原始 key 的哈希值不会变化。")]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://docs.python.org/3.7/using/cmdline.html#envvar-PYTHONHASHSEED",target:"_blank",rel:"noopener noreferrer"}},[t._v("PYTHONHASHSEED"),a("OutboundLink")],1),t._v(" "),a("ul",[a("li",[t._v("If this variable is not set or set to random, a "),a("strong",[t._v("random value")]),t._v(" is used to "),a("strong",[t._v("seed the hashes")]),t._v(" of "),a("em",[t._v("str, bytes and datetime")]),t._v(" objects.")]),t._v(" "),a("li",[t._v("If PYTHONHASHSEED is set to an integer value, it is "),a("strong",[t._v("used as a fixed seed")]),t._v(" for generating the "),a("code",[t._v("hash()")]),t._v(" of the types covered by the hash randomization.")]),t._v(" "),a("li",[t._v("Its purpose is to "),a("strong",[t._v("allow repeatable hashing")]),t._v(", such as for selftests for the interpreter itself, or to allow a cluster of python processes to share hash values.")]),t._v(" "),a("li",[t._v("The integer must be a "),a("strong",[t._v("decimal number")]),t._v(" in the range [0,4294967295]. Specifying the "),a("strong",[t._v("value 0")]),t._v(" will "),a("em",[t._v("disable hash randomization")]),t._v(".")])])])]),t._v(" "),a("p",[t._v("哈希链接表（hash chaining table）中，假设待存储对象有 n 个，哈希表长度为 m，则哈希链接表中的每个链表的期望长度为 n/m。记 "),a("code",[t._v("\\Alpha = n/m")]),t._v("，称为此哈希表的 "),a("strong",[t._v("load factor 加载因子")]),t._v("。可以根据哈希表当前的 加载因子 来决定动态地 扩张 / 缩减 表大小。")]),t._v(" "),a("p",[t._v("Java JDK 1.7 的 HashMap 数据结构的加载因子为 0.75，官方文档解释如下：")]),t._v(" "),a("p",[t._v("As a general rule, the "),a("strong",[t._v("default load factor (.75)")]),t._v(" offers a "),a("strong",[t._v("good tradeoff between time and space costs")]),t._v(". Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the HashMap class, including get and put). The expected number of entries in the map and its load factor should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum number of entries divided by the load factor, no rehash operations will ever occur.")]),t._v(" "),a("ul",[a("li",[t._v("哈希链接表操作\n"),a("ul",[a("li",[t._v("搜索 search：先将原始的 key 通过 hash 映射成哈希表下标、找到对应的链表，耗时 O(1)；然后在链表中查询（链表结点中存储了原始数据对象，此时可以对 key 值进行精确匹配），耗时 O(l)，l 为此链表长度，其期望值为加载因子 Alpha。")]),t._v(" "),a("li",[t._v("插入 insert：先将原始的 key 通过 hash 映射成哈希表下标、找到对应的链表，耗时 O(1)；然后在链表首部（如果不考虑排序）插入，耗时 O(1)。")]),t._v(" "),a("li",[t._v("删除 delete：先搜索，耗时 O(l)；搜索到了后修改链表结构，耗时 O(1)。")])])])]),t._v(" "),a("p",[t._v("如果 1. 采用随机因子使得哈希值尽量服从均匀分布；2. 根据加载因子动态扩缩哈希表（使得 m > n 且 m = O(n)）。那么上述 search 和 delete 操作的时间复杂度都能特别接近于 O(1)，同 insert 操作一样。")]),t._v(" "),a("h2",{attrs:{id:"散列函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#散列函数"}},[t._v("#")]),t._v(" 散列函数")]),t._v(" "),a("p",[t._v("一个好的散列函数应该(近似地)满足简单均匀散列假设：每个关键字都等可能地被散列到 m 个槽位中的任何一个（均匀分布），并与其它关键字已散列到哪个槽位无关（独立采样）。遗憾的是，一般无法检查这一条件是否成立，因为很少能知道关键字散列所满足的概率分布，而且各关键字可能并不是完全独立的。")]),t._v(" "),a("p",[t._v("有时，我们知道关键字的概率分布。例如，如果各关键字都是随机的实数 k，它们独立均匀地分布于 0 <= k < 1 范围中，那么散列函数 "),a("code",[t._v("h(k) = \\floor(km)")]),t._v(" 就能满足简单均匀散列的假设条件。实际上，桶排序就正是这样做的。")]),t._v(" "),a("p",[t._v("在实际应用中，常常可以运用启发式方法来构造性能好散列函数。设计过程中，可以利用关键字分布的有用信息。例如，在一个编译器的符号表中，关键字都是字符串，表示程序中的标识符。一些很相近的符号经常会出现在同一个程序中，如 pt 和 pts。好的散列函数应能将这些相近符号散列到相同槽中的可能性最小化。")]),t._v(" "),a("p",[t._v("一种好的方法导出的散列值，在某种程度上应独立于数据可能存在的任何模式。例如，“除法散列”用一个特定的素数来除任何所给的关键字，所得的余数即为该关键字的散列值。假定所选择的素数与关键字分布中的任何模式都是无关的，这种方法常常可以给出好的结果。")]),t._v(" "),a("p",[t._v("另外，散列函数的某些应用可能会要求比简单均匀散列更强的性质。例如，可能希望某些很近似的关键字具有截然不同的散列值（使用后文所述的线性探查技术时，这一特性特别有用）。后文的全域散列 Universal Hashing 通常能够提供这些性质。")]),t._v(" "),a("p",[t._v("多数散列函数都假定关键字的全域为自然数集 N = {0, 1, 2, ...}。因此，如果所给关键字不是自然数，通常需要前文所述的 Pre-Hashing 操作将之转换为自然数，从而直接作为哈希表的下标来使用。")]),t._v(" "),a("h3",{attrs:{id:"除法散列法-division-hashing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#除法散列法-division-hashing"}},[t._v("#")]),t._v(" 除法散列法 Division Hashing")]),t._v(" "),a("p",[a("code",[t._v("h(k) = k \\mod m")])]),t._v(" "),a("h3",{attrs:{id:"乘法散列法-multiplication-hashing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#乘法散列法-multiplication-hashing"}},[t._v("#")]),t._v(" 乘法散列法 Multiplication Hashing")]),t._v(" "),a("p",[a("code",[t._v("h(k) = \\floor(m (kA \\mod 1))")])]),t._v(" "),a("p",[t._v("其中，A 被某个被随机选定的数字（Knuth 建议 "),a("code",[t._v("A = (\\sqrt(5) - 1) / 2")]),t._v("，约等于 0.6180339887...），"),a("code",[t._v("kA mod 1")]),t._v(" 表示取 kA 乘积的小数部分，等同于 "),a("code",[t._v("kA - \\floor(kA)")]),t._v("。")]),t._v(" "),a("p",[t._v("另外，这个式子也等同于 "),a("code",[t._v("h(k) = ((kA) \\mod 2^w) >> (w - r)")])]),t._v(" "),a("p",[t._v("w 是当前机器的字长（一个字所占的 bit 数），k 和 A 的乘积 kA 为两个字长（即 2w 双字）。kA 模 2^w 即为取低 w 位的单字（这里假设 endianness 字节顺序是 little-endian 小端模式，即数据的高(低)字节保存在内存的高(低)地址中，而非 big-endian 大端模式）。最后将前述结果右移 (w-r) 位，即只取该单字中的高 r 位（m = 2^r），因此最终的结果是一个位于闭区间 [0, m-1] 的自然数。")]),t._v(" "),a("h3",{attrs:{id:"全域散列法-universal-hashing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#全域散列法-universal-hashing"}},[t._v("#")]),t._v(" 全域散列法 Universal Hashing")]),t._v(" "),a("p",[a("code",[t._v("h(k) = ((kA + b) \\mod p) \\mod m")])]),t._v(" "),a("p",[t._v("其中 p 为某个大素数（大于全域），a 和 b 是从闭区间 [0, p-1] 中随机取值的。大素数是可以在 Polynomial Time 多项式时间内找到的。")]),t._v(" "),a("p",[t._v("可以证明，对于全域散列法，在最坏情况下，冲突的概率是 1/m。即：对任意 k1 != k2 而言，Pr{h(k1) = h(k2)} = 1/m。")]),t._v(" "),a("h2",{attrs:{id:"解决冲突-开放寻址法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解决冲突-开放寻址法"}},[t._v("#")]),t._v(" 解决冲突 - 开放寻址法")]),t._v(" "),a("p",[t._v("开放寻址法 Open Addressing 是处理冲突的另一种方法。")]),t._v(" "),a("h2",{attrs:{id:"散列表的动态扩缩-grow-shrink"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#散列表的动态扩缩-grow-shrink"}},[t._v("#")]),t._v(" 散列表的动态扩缩 grow/shrink")]),t._v(" "),a("p",[t._v("虽然知道 m 应该等于 O(n)，但是 n 是动态的，所以 m 也应是动态的，才能实用。")]),t._v(" "),a("p",[t._v("另外，Python 的 list 数据结构也支持动态扩缩，有时也被称为 resizable array，其原理与哈希表的扩缩也是类似的，根据当前的 load factor 加载因子 n/m 来决定。顺带一提，Python 的 "),a("code",[t._v("append(obj)")]),t._v(" 尾部追加操作、"),a("code",[t._v("pop(index=-1)")]),t._v(" 尾部删除都是 O(1) 的时间，但是在任意位置（尤其是首部）"),a("code",[t._v("insert(index, obj)")]),t._v(" 插入、"),a("code",[t._v("pop(index)")]),t._v(" 删除、"),a("code",[t._v("remove(obj)")]),t._v(" 移除元素的耗时均为 O(n)，因为中间位置删除后，需要将后面的元素一一往左“挪动”。")]),t._v(" "),a("p",[t._v("不过与普通的 list 不同，哈希表在扩张或者缩小后，都需要 rehash 重新散列，所以为了避免过多的 rehash 影响实际性能，初始哈希表不能太小，扩缩哈希表的策略要精心设计。")]),t._v(" "),a("p",[t._v("重新建立哈希表耗时 O(n + m + m')。加 m 是因为要查看原本长度为 m 的哈希表中所有的 slot，而 m' 是新的哈希表大小。")]),t._v(" "),a("p",[t._v("注意：在建立新的哈希表前，要更换哈希函数（具体实现里，只用把哈希函数的某一个参数从 m 改为 m' 即可），记为 h'。")]),t._v(" "),a("p",[t._v("一般来说，扩张哈希表时，m' = 2m，这被称为 Table Doubling。考虑哈希表从 0 开始不断扩张，进行 n 次插入，重建哈希表的总耗时为 O(1 + 2 + 4 + ... + n) = O(n)，所以每次插入所造成的哈希表扩张的 Amortized Time 摊还时间为 O(1)。")]),t._v(" "),a("p",[t._v("“摊还时间”的可以这么理解：就是按各 operation 操作的总时间进行平均。比如如果 k 次操作的总时间为 k T(n)，则单次操作的摊还时间就是 T(n)。进行摊还分析是很实用的，因为实际数据结构存储的元素往往是动态变化的。可以参考《CLRS》的第 17 章，也可以查看"),a("a",{attrs:{href:"https://www.youtube.com/watch?v=3MpzavN3Mco",target:"_blank",rel:"noopener noreferrer"}},[t._v("此视频"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("p",[t._v("同理，考虑哈希表缩小，k 次删除操作，每次删除操作所造成的哈希表缩小的摊还时间也为 O(1)。")]),t._v(" "),a("p",[t._v("如果加载因子为 1，即 n = m 时，再插入就扩张；加载因子为 1/2，即 n = m/2 时，就减半缩小，则有可能会“震荡”：比如当前有 n=8 个元素，m 也等于 8。插入第 9 个元素时，会扩张表 m' = 2m = 16。此后如果立即删除一个元素，则此时 n=8 = m'/2，又需要缩小表。")]),t._v(" "),a("p",[t._v("更好的方案是：当加载因子为 1/4，即 n = m/4 时，才减半缩小 m' = m/2，这样缩小之后还有 m/4 = m'/2 的空间是空闲的，此后进行的 m'/2 次插入也不会引起扩张。此时，可以证明，每次插入/删除操作所造成的哈希表扩张/缩小的摊还时间为 O(1)。")]),t._v(" "),a("p",[t._v("当然，如果预先知道当前数据量 n，可以直接初始化哈希表为 O(n)，比如 m = n 或者 2n 是个不错的初始化方式。")]),t._v(" "),a("h2",{attrs:{id:"完全散列-perfect-hashing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#完全散列-perfect-hashing"}},[t._v("#")]),t._v(" 完全散列 Perfect Hashing")]),t._v(" "),a("p",[t._v("完全散列 Perfect Hashing。当关键字集合时静态存储（即关键字集合一旦存入后就不再改变，没有 insert 和 delete 操作，只有 search 操作），完全散列能够在 O(1) 的最坏时间内完成关键字查找。")]),t._v(" "),a("h2",{attrs:{id:"应用场景"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#应用场景"}},[t._v("#")]),t._v(" 应用场景")]),t._v(" "),a("ul",[a("li",[t._v("search engine\n"),a("ul",[a("li",[t._v("比如搜索引擎输入框的 spelling correction 词语纠错，原本所有词汇都在一个已经建立好的词典（哈希表）中，在用户输入英文词语后，如果该词语在字典中搜索不到，就有可能是用户输入了错词。那么此时(以一定策略)修改词语中的某些字母、反复查询字典，找到正确的拼写，并提示用户。")])])]),t._v(" "),a("li",[t._v("doc dist")]),t._v(" "),a("li",[t._v("databases")]),t._v(" "),a("li",[t._v("compilers & interpreters")]),t._v(" "),a("li",[t._v("virtual memory / MMU")]),t._v(" "),a("li",[t._v("network router / server")]),t._v(" "),a("li",[t._v("...")])]),t._v(" "),a("p",[t._v("更细粒度的应用，比如：")]),t._v(" "),a("ul",[a("li",[t._v("substring search\n"),a("ul",[a("li",[t._v("Unix 中的 grep 命令即是如此，见"),a("a",{attrs:{href:"./string"}},[t._v("字符串")]),t._v(" 的 Rabin-Karp 算法")])])]),t._v(" "),a("li",[t._v("string commonality（比如比较两字符串的 edit distance 编辑距离）")]),t._v(" "),a("li",[t._v("file and dictionary synchronization（比如 Unix 中的 rsync 命令、unison 命令，以及 Dropbox 应用）\n"),a("ul",[a("li",[t._v("使用 hashing 操作来记录文档的变化")])])]),t._v(" "),a("li",[t._v("cryptography & digital signature & authentication")])]),t._v(" "),a("h2",{attrs:{id:"设计-细节"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#设计-细节"}},[t._v("#")]),t._v(" 设计 & 细节")]),t._v(" "),a("h3",{attrs:{id:"算法流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#算法流程"}},[t._v("#")]),t._v(" 算法流程")]),t._v(" "),a("h3",{attrs:{id:"实现细节"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实现细节"}},[t._v("#")]),t._v(" 实现细节")]),t._v(" "),a("h2",{attrs:{id:"代码范例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#代码范例"}},[t._v("#")]),t._v(" 代码范例")]),t._v(" "),a("h3",{attrs:{id:"python"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("p",[t._v("Python 环境：Python 3.7")]),t._v(" "),a("h3",{attrs:{id:"hash-table"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash-table"}},[t._v("#")]),t._v(" Hash Table")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\n")])])]),a("h2",{attrs:{id:"参考资料"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),a("ul",[a("li",[t._v("Introduction to Algorithm (aka CLRS) Third Edition - Chapter 11")]),t._v(" "),a("li",[t._v("MIT 6.006 Introduction to Algorithms, Fall 2011\n"),a("ul",[a("li",[a("ol",{attrs:{start:"8"}},[a("li",[a("a",{attrs:{href:"https://www.youtube.com/watch?v=0M_kIqhwbFo",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hashing with Chaining"),a("OutboundLink")],1)])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"9"}},[a("li",[a("a",{attrs:{href:"https://www.youtube.com/watch?v=BRO7mVIFt08",target:"_blank",rel:"noopener noreferrer"}},[t._v("Table Doubling, Karp-Rabin"),a("OutboundLink")],1)])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"10"}},[a("li",[a("a",{attrs:{href:"https://www.youtube.com/watch?v=rvdJDijO2Ro",target:"_blank",rel:"noopener noreferrer"}},[t._v("Open Addressing, Cryptographic Hashing"),a("OutboundLink")],1)])])])])]),t._v(" "),a("li",[t._v("MIT 6.046J Design and Analysis of Algorithms, Spring 2015\n"),a("ul",[a("li",[a("ol",{attrs:{start:"8"}},[a("li",[t._v("Randomization: "),a("a",{attrs:{href:"https://www.youtube.com/watch?v=z0lJ2k0sl1g",target:"_blank",rel:"noopener noreferrer"}},[t._v("Universal & Perfect Hashing"),a("OutboundLink")],1)])])])])]),t._v(" "),a("li",[t._v("MIT 6.854J Advanced Algorithms\n"),a("ul",[a("li",[t._v("Lecture 06, 09/18: "),a("a",{attrs:{href:"https://www.youtube.com/watch?v=z8DD-ikAjzM",target:"_blank",rel:"noopener noreferrer"}},[t._v("Hashing"),a("OutboundLink")],1)])])]),t._v(" "),a("li",[t._v("MIT 6.854 (Advanced Algorithms), Spring 2016\n"),a("ul",[a("li",[t._v("Lecture 3: "),a("a",{attrs:{href:"https://www.youtube.com/watch?v=hM547xRIdzc",target:"_blank",rel:"noopener noreferrer"}},[t._v("Consistent Hashing and Random Trees"),a("OutboundLink")],1)])])])])])}),[],!1,null,null,null);e.default=s.exports}}]);