(window.webpackJsonp=window.webpackJsonp||[]).push([[19],{399:function(t,s,n){"use strict";n.r(s);var a=n(28),e=Object(a.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"algorithm-data-structure-interval-tree"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#algorithm-data-structure-interval-tree"}},[t._v("#")]),t._v(" Algorithm - Data Structure - Interval Tree")]),t._v(" "),n("p",[t._v("Create Date: 2020.05.24")]),t._v(" "),n("p",[t._v("Last Update Date: 2020.05.26")]),t._v(" "),n("p",[t._v("By "),n("a",{attrs:{href:"https://yuweiyin.github.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("YuweiYin"),n("OutboundLink")],1)]),t._v(" "),n("h2",{attrs:{id:"简介"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),n("p",[t._v("区间树 (Interval Tree)")]),t._v(" "),n("p",[t._v("与 "),n("a",{attrs:{href:"./order-statistic-tree"}},[t._v("顺序统计树")]),t._v(" (Order Statistic Tree, OST) 相似，区间树也是基于 "),n("a",{attrs:{href:"./red-black-tree"}},[t._v("红黑树")]),t._v(" (Red Black Tree, RBT) 数据结构的扩张，用于支持由区间构成的动态集合上的一些操作。")]),t._v(" "),n("p",[t._v("实数域 R 上的 "),n("strong",[t._v("闭区间")]),t._v(" (closed interval) 是一个实数的有序对 [t1, t2]，其中 t1 <= t2。区间 [t1, t2] 表示了集合 $ {t \\in R: t1 <= t <= t2} $。"),n("strong",[t._v("开")]),t._v("(open)区间 和 "),n("strong",[t._v("半开")]),t._v("(half-open)区间 分别略去了集合的两个和一个端点。在此后的讨论中，均假设区间都是闭的。")]),t._v(" "),n("p",[t._v("区间便于表示占用一个连续时间段的一些事件。例如：查询一个由时间区间数据（左右断点 pair）构成的数据库，找出给定时间区间内发生了什么事件。")]),t._v(" "),n("h2",{attrs:{id:"设计"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#设计"}},[t._v("#")]),t._v(" 设计")]),t._v(" "),n("p",[t._v("把闭区间 [t1, t2] 表示成一个对象 inter，其中属性 inter.low = t1 为"),n("strong",[t._v("低端点")]),t._v("(low endpoint)，属性 inter.high = t2 为"),n("strong",[t._v("高端点")]),t._v("(high endpoint)。如果两个对象 inter1 和 inter2 的区间"),n("strong",[t._v("交集不为空")]),t._v("，则称这两个"),n("strong",[t._v("区间重叠")]),t._v("(overlap)。对对象属性而言，重叠意味着 inter1.low <= inter2.high 并且 inter2.low <= inter1.high。")]),t._v(" "),n("p",[t._v("任何两个区间 inter1 和 inter2 满足"),n("strong",[t._v("区间三分律")]),t._v(" (interval trichotomy)，即下述三条性质有且仅有其一成立：")]),t._v(" "),n("ol",[n("li",[t._v("inter1 和 inter2 重叠。\n"),n("ul",[n("li",[t._v("即：inter1.low <= inter2.high 并且 inter2.low <= inter1.high")])])]),t._v(" "),n("li",[t._v("inter1 在 inter2 左边。\n"),n("ul",[n("li",[t._v("即：inter1.high < inter2.low")])])]),t._v(" "),n("li",[t._v("inter1 在 inter2 右边。\n"),n("ul",[n("li",[t._v("即：inert1.low > inter2.high")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:"/img/info_technology/algorithm/data_structure/interval-tree-1.png",alt:"interval-tree-1"}})]),t._v(" "),n("p",[t._v("区间查询 Range Query 任务中，与区间树类似的比如 "),n("a",{attrs:{href:"./segment-tree"}},[t._v("线段树")]),t._v(" (Segment Tree, ST)。但线段树一般是针对静态的数据，一旦数据量变化，就需要花费 O(n) 的时间重建。而区间树是一种基于红黑树的动态集合数据结构。")]),t._v(" "),n("p",[t._v("区间树中每个树结点 x 都包含一个区间属性 inter，此属性可以设置为一个元组对象 tuple 或者一种新的结构体对象，视具体需求而定。")]),t._v(" "),n("p",[t._v("区间树主要支持如下操作：")]),t._v(" "),n("ul",[n("li",[n("code",[t._v("interval_insert(T, x)")]),t._v(" "),n("ul",[n("li",[t._v("将包含区间属性 inter 的元素 x 插入到区间树 T 中")])])]),t._v(" "),n("li",[n("code",[t._v("interval_delete(T, x)")]),t._v(" "),n("ul",[n("li",[t._v("从区间树 T 中删除元素 x")])])]),t._v(" "),n("li",[n("code",[t._v("interval_search(T, target_inter)")]),t._v(" "),n("ul",[n("li",[t._v("返回一个指向区间树 T 中元素 x 的指针，使 x.inter 与 target_inter 重叠")]),t._v(" "),n("li",[t._v("若此元素不存在，则返回 None")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:"/img/info_technology/algorithm/data_structure/interval-tree-2.png",alt:"interval-tree-2"}})]),t._v(" "),n("h3",{attrs:{id:"扩张步骤"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#扩张步骤"}},[t._v("#")]),t._v(" 扩张步骤")]),t._v(" "),n("ol",[n("li",[t._v("基础数据结构：\n"),n("ul",[n("li",[t._v("选择红黑树作为基础数据结构，其每个结点 x 包含一个区间属性 x.inter，且 x 的关键字 key 为区间的低端点 x.inter.low。")]),t._v(" "),n("li",[t._v("因此，该数据结构按中序遍历列出的就是按低端点的次序排列的各区间。")])])]),t._v(" "),n("li",[t._v("附加信息：\n"),n("ul",[n("li",[t._v("每个结点 x 中除了自身的区间信息 以及红黑树本身的信息外，还包含一个数值 x.max，表示以 x 为根的子树中所有区间端点的最大值。")])])]),t._v(" "),n("li",[t._v("对信息的维护：\n"),n("ul",[n("li",[t._v("通过给定区间的 x.inter 和结点 x 的子结点的 max 值，可以确定 x.max 值")]),t._v(" "),n("li",[t._v("x.max = max(x.inter.high, x.left.max, x.right.max)")]),t._v(" "),n("li",[t._v("由于更新 x 的附加信息仅依赖于本结点及其孩子结点 这 3 个结点的信息，所以可以保证插入和删除时对附加信息的维护也是 O(log n) 时间的。")])])]),t._v(" "),n("li",[t._v("设计新的操作：\n"),n("ul",[n("li",[t._v("对于插入和删除，只需维护 max 信息即可")]),t._v(" "),n("li",[t._v("利用附加信息 max，可以设计的新操作是 "),n("code",[t._v("interval_search(T, target_inter)")]),t._v(" 找出区间树 T 中与区间 target_inter 重叠的那个结点。若此元素不存在，则返回 None")])])])]),t._v(" "),n("h3",{attrs:{id:"建立区间树"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#建立区间树"}},[t._v("#")]),t._v(" 建立区间树")]),t._v(" "),n("p",[t._v("以 kv_array 中的每个元素为 [key, value] 数组，构建树结点。树结点设计如下：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TreeNode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inter_low"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inter_high"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_low  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 键，区间树的关键字 key 即为区间的低端点")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("val "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" val        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 值，树结点存储的值，可以为任意对象")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" color    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 结点的颜色，True 代表红色(默认)，False 代表黑色")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左孩子指针")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 右孩子指针")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 父结点指针")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''上面是红黑树原本的所需的树结点属性'''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''下面是顺序统计树扩张红黑树功能所需的属性'''")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inter_low"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inter_high"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# interval 区间属性 (这里默认为闭区间)")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_high             "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以本结点为根的子树的 所有区间端点的最大值")]),t._v("\n")])])]),n("h3",{attrs:{id:"区间查询"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#区间查询"}},[t._v("#")]),t._v(" 区间查询")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查询区间树中是否存在与闭区间 target_interval 有重叠的区间")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("interval_search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" \\\n            "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 ptr 结点的区间与目标区间 target_interval 有重叠，则返回 ptr")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 有重叠：inter1.low <= inter2.high 并且 inter2.low <= inter1.high")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ptr\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果无重叠，则往左或往右 继续搜索")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果左孩子存在 (不是哨兵)，且左子树的区间端点最大值超过 目标区间的低端点，")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 表示左侧有与目标区间重合的区间结点，则往左继续搜索")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 注意到：由于区间是连续的，所以此时不可能与右子树中的任何区间重叠了")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 否则，左孩子不存在 (是哨兵)，或者左子树的区间端点最大值不及 目标区间的低端点，")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 表示左侧的结点已经不可能与目标区间有重合了，则往右继续搜索")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果出了循环、到了这一步，表示找不到")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# BST 树为空树，找不到目标结点")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n")])])]),n("h3",{attrs:{id:"左旋-右旋"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#左旋-右旋"}},[t._v("#")]),t._v(" 左旋/右旋")]),t._v(" "),n("p",[t._v("在左旋和右旋操作中，返回新父亲 node_y 之前，加上相同的语句，维护 max_end 属性：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 维护区间树的属性 max_end (注意先更新此时的子结点 node_x, 后更新 node_y)")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对某一个结点进行 max_end 维护的总时间复杂度为 O(log n)，不增加渐近量级")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnode_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nnode_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("例如完整的左旋操作：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：左旋。返回替代了 node 的新结点")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(1)")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_left_rotate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对 x 进行左旋，即让 x 的右孩子 y (x.right) 成为 x 的父结点，且 x 等于 y.left。")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 而 y 结点原本的左孩子变为新 x 的右孩子")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 x 是 BST 树根，那么树根要更换")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调整树结构")]),t._v("\n        node_y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n        node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置 node_y 的父结点（互相关联）")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n\n        node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 结点原本的左孩子变为新 x 的右孩子")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x\n\n        node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x\n        node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 维护区间树的属性 max_end (注意先更新此时的子结点 node_x, 后更新 node_y)")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对某一个结点进行 max_end 维护的总时间复杂度为 O(log n)，不增加渐近量级")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回替代了 node 的结点 node_y")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node_y\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n")])])]),n("h3",{attrs:{id:"插入"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#插入"}},[t._v("#")]),t._v(" 插入")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 TreeNode 对象增加结点")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 增加后（每次都增加叶结点），调用 rb_insert_fixup 维护红黑性质")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("interval_insert")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    insert_interval "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n    insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n    insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前 BST 为空，则直接设置 self.bst 结点，完成插入")]),t._v("\n        insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n        insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用 ptr 指针从 root 结点（一般设为 self.bst）开始向下搜索插入位置")]),t._v("\n        ptr_p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ptr_p 记录 ptr 的父亲")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入过程中维护区间树的 max_end 属性")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr_p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ptr 会是新结点的祖先结点，所以根据高端点 决定是否需要更新本结点的 max_end")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据低端点 (即 key) 来决定往左还是往右插入")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 key 决定该插入到左边还是右边")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node\n        insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr_p\n\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_insert_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入后维护红黑性质")]),t._v("\n")])])]),n("p",[t._v("原本的 "),n("code",[t._v("_rb_insert_fixup")]),t._v(" 函数无需改动。")]),t._v(" "),n("h3",{attrs:{id:"删除"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#删除"}},[t._v("#")]),t._v(" 删除")]),t._v(" "),n("p",[t._v("按结点 TreeNode 对象删除结点，先判断某结点是否存在：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 TreeNode 精确匹配结点，用于删除结点时检查某结点是否存在于树中")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果搜索到了，则返回 True，如果搜索不到，则返回 False")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("exact_search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" target_node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到了目标结点，返回此 TreeNode")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" target_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果新结点 key 值小于当前结点，则应该往左走")]),t._v("\n                ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果新结点 key 值大于当前结点，则应该往右走")]),t._v("\n                ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果出了循环、到了这一步，表示找不到")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找不到目标结点")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n")])])]),n("p",[t._v("删除某结点后，逐级向上维护 max_end 属性：")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除某结点后，逐级向上维护 max_end 属性")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_interval_delete_fix_max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n")])])]),n("p",[t._v("原本的 "),n("code",[t._v("_rb_delete_fixup")]),t._v(" 函数无需改动。")]),t._v(" "),n("h2",{attrs:{id:"代码范例"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#代码范例"}},[t._v("#")]),t._v(" 代码范例")]),t._v(" "),n("h3",{attrs:{id:"python"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#python"}},[t._v("#")]),t._v(" Python")]),t._v(" "),n("p",[t._v("Python 环境：Python 3.7")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#!/usr/bin/env python")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -*- coding:utf-8 -*-")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""=================================================\n@Project : algorithm/data_structure\n@File    : interval-tree.py\n@Author  : YuweiYin\n@Date    : 2020-05-24\n=================================================="""')]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# import gc")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" sys\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" time\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n区间树 (Interval Tree)\n\n参考资料：\nIntroduction to Algorithm (aka CLRS) Third Edition - Chapter 14\n"""')]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TreeNode")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inter_low"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inter_high"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_low  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 键，区间树的关键字 key 即为区间的低端点")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("val "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" val        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 值，树结点存储的值，可以为任意对象")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" color    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 结点的颜色，True 代表红色(默认)，False 代表黑色")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左孩子指针")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 右孩子指针")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 父结点指针")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''上面是红黑树原本的所需的树结点属性'''")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''下面是顺序统计树扩张红黑树功能所需的属性'''")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inter_low"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inter_high"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# interval 区间属性 (这里默认为闭区间)")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_high             "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以本结点为根的子树的 所有区间端点的最大值")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IntervalTree")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 构造 区间树 (Interval Tree)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(n log n)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        neg_inf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x3f3f3f3f")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 负无穷，设置为哨兵的区间值")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 二叉搜索树结构 self.bst 树根")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 标志着当前 BST 是否为空")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_key_list "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 已排好序的关键字列表")]),t._v("\n\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("neg_inf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" neg_inf"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 黑色的哨兵结点")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 哨兵的父结点仍为自己")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil     "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 哨兵的左孩子仍为自己")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 哨兵的右孩子仍为自己")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if isinstance(kv_array, list) and len(kv_array) > 0:")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     for kv in kv_array:")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#         # 对区间树来说，构造数组中的 k 即为 区间的低高端点 (inter_low, inter_high)")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#         assert isinstance(kv, list) and len(kv) == 2")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#         assert isinstance(kv[0], tuple) and len(kv[0]) == 2")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#         assert kv[0][0] <= kv[0][1]  # 低端点 <= 高端点")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#         self.rb_insert(kv[0], kv[1])")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     # 中序遍历，获取 sorted_key_list 升序数组/列表")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     self.update_sorted_key_list()")]),t._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 按结点对象列表插入")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" interval_node "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_insert"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("interval_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中序遍历，获取 sorted_key_list 升序数组/列表")]),t._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''下面是顺序统计树的扩张功能函数'''")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 查询区间树中是否存在与闭区间 target_interval 有重叠的区间")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("interval_search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" \\\n                "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 ptr 结点的区间与目标区间 target_interval 有重叠，则返回 ptr")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 有重叠：inter1.low <= inter2.high 并且 inter2.low <= inter1.high")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ptr\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果无重叠，则往左或往右 继续搜索")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果左孩子存在 (不是哨兵)，且左子树的区间端点最大值超过 目标区间的低端点，")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 表示左侧有与目标区间重合的区间结点，则往左继续搜索")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 注意到：由于区间是连续的，所以此时不可能与右子树中的任何区间重叠了")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" target_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 否则，左孩子不存在 (是哨兵)，或者左子树的区间端点最大值不及 目标区间的低端点，")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 表示左侧的结点已经不可能与目标区间有重合了，则往右继续搜索")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果出了循环、到了这一步，表示找不到")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# BST 树为空树，找不到目标结点")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 TreeNode 精确匹配结点，用于删除结点时检查某结点是否存在于树中")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果搜索到了，则返回 True，如果搜索不到，则返回 False")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("exact_search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" target_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("target_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" target_node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到了目标结点，返回此 TreeNode")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" target_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果新结点 key 值小于当前结点，则应该往左走")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果新结点 key 值大于当前结点，则应该往右走")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果出了循环、到了这一步，表示找不到")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找不到目标结点")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''下面是红黑树原本的代码 + 维护新性质所需的额外操作'''")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 中序遍历，将 BST 结点的 key 值（升序排列）存储于 sorted_key_list")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(n)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_inorder_traversal")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" root "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_inorder_traversal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_inorder_traversal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调用中序遍历，更新 sorted_key_list")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("update_sorted_key_list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_key_list "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_inorder_traversal"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获得 sorted_key_list")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_sorted_key_list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_key_list\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：左旋。返回替代了 node 的新结点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(1)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_left_rotate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对 x 进行左旋，即让 x 的右孩子 y (x.right) 成为 x 的父结点，且 x 等于 y.left。")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 而 y 结点原本的左孩子变为新 x 的右孩子")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 x 是 BST 树根，那么树根要更换")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调整树结构")]),t._v("\n            node_y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置 node_y 的父结点（互相关联）")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n\n            node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 结点原本的左孩子变为新 x 的右孩子")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x\n\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x\n            node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 维护区间树的属性 max_end (注意先更新此时的子结点 node_x, 后更新 node_y)")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对某一个结点进行 max_end 维护的总时间复杂度为 O(log n)，不增加渐近量级")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回替代了 node 的结点 node_y")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node_y\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：右旋。返回替代了 node 的新结点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(1)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_right_rotate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对 x 进行右旋，即让 x 的左孩子 y (x.left) 成为 x 的父结点，且 x 等于 y.right。")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 而 y 结点原本的右孩子变为新 x 的左孩子")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 x 是 BST 树根，那么树根要更换")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 调整树结构")]),t._v("\n            node_y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 设置 node_y 的父结点（互相关联）")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node_x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n\n            node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 结点原本的右孩子变为新 x 的左孩子")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x\n\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_x\n            node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_y\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 维护区间树的属性 max_end (注意先更新此时的子结点 node_x, 后更新 node_y)")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对某一个结点进行 max_end 维护的总时间复杂度为 O(log n)，不增加渐近量级")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node_y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回替代了 node 的结点 node_y")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" node_y\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 key 值搜索结点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果搜索到了，则返回结点 TreeNode，如果搜索不到，则返回 None")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("search")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" search_key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到了目标结点，返回此 TreeNode")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" ptr\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" search_key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果新结点 key 值小于当前结点，则应该往左走")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果新结点 key 值大于当前结点，则应该往右走")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果出了循环、到了这一步，表示找不到")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# BST 树为空树，找不到目标结点")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：插入之后，逐级向上进行红黑性质维护")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据当前结点的父结点、爷爷结点、叔叔结点的颜色，分 3 种情况，用旋转操作来调整平衡")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_rb_insert_fixup")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当前结点 node 为新插入的结点，是红色的")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的爷爷结点必为树结点 (红黑树性质)")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的爷爷结点为 nil 结点，而且父结点存在")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这表示父结点为树根，且根是红色。只需要把根改为黑色即可")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的爷爷结点为树结点，且非 nil")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 node 的父结点是 node 爷爷结点的左孩子")]),t._v("\n                        uncle "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uncle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" uncle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 1: 父结点为红色、父结点是爷爷结点的左孩子、叔叔结点也为红色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这种情况可以直接处理掉")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置父结点的颜色为黑色")]),t._v("\n                            uncle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置叔叔结点的颜色为黑色")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置爷爷结点颜色为红色")]),t._v("\n                            node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 上移至其爷爷结点")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时：父结点为红色、父结点是爷爷结点的左孩子、叔叔结点不存在或者为黑色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 2: 父结点为红色、父结点是爷爷结点的左孩子、")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 叔叔结点不存在或者为黑色、当前结点是父结点的右孩子")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这种情况先转换成 case 3，然后再处理掉")]),t._v("\n                                node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 上移至其父（旋转后会降下来）")]),t._v("\n                                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 左旋，"拉直" 呈 LL 型')]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 3: 父结点为红色、父结点是爷爷结点的左孩子、")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 叔叔结点不存在或者为黑色、当前结点是父结点的左孩子")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改父结点为黑色")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改爷爷结点为红色")]),t._v("\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 右旋爷爷结点")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 node 的父结点是 node 爷爷结点的右孩子（与前述操作呈镜像处理，减少注释）")]),t._v("\n                        uncle "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uncle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" uncle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 1': 父结点为红色、父结点是爷爷结点的右孩子、叔叔结点也为红色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这种情况可以直接处理掉")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置父结点的颜色为黑色")]),t._v("\n                            uncle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置叔叔结点的颜色为黑色")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 置爷爷结点颜色为红色")]),t._v("\n                            node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 上移至其爷爷结点")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时：父结点为红色、父结点是爷爷结点的右孩子、叔叔结点不存在或者为黑色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 2': 父结点为红色、父结点是爷爷结点的右孩子、")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 叔叔结点不存在或者为黑色、当前结点是父结点的左孩子")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这种情况先转换成 case 3，然后再处理掉")]),t._v("\n                                node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 上移至其父（旋转后会降下来）")]),t._v("\n                                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 右旋，"拉直" 呈 RR 型')]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 3': 父结点为红色、父结点是爷爷结点的右孩子、")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 叔叔结点不存在或者为黑色、当前结点是父结点的右孩子")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改父结点为黑色")]),t._v("\n                            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改爷爷结点为红色")]),t._v("\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左旋爷爷结点")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# while 循环结束、处理完毕，如果此时树根存在，则置为黑色")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：新建树结点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_create_new_node")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" new_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        new_node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" new_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("new_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" color"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n        new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" new_node\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助函数：清除某个结点的所有指针域")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[t._v("@staticmethod")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_clear_node_link")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 TreeNode 对象增加结点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 增加后（每次都增加叶结点），调用 rb_insert_fixup 维护红黑性质")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("interval_insert")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        insert_interval "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n        insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n        insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前 BST 为空，则直接设置 self.bst 结点，完成插入")]),t._v("\n            insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n            insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用 ptr 指针从 root 结点（一般设为 self.bst）开始向下搜索插入位置")]),t._v("\n            ptr_p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ptr_p 记录 ptr 的父亲")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入过程中维护区间树的 max_end 属性")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr_p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ptr 会是新结点的祖先结点，所以根据高端点 决定是否需要更新本结点的 max_end")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据低端点 (即 key) 来决定往左还是往右插入")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 key 决定该插入到左边还是右边")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_node\n            insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr_p\n\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_insert_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入后维护红黑性质")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 key 值增加结点")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 增加后（每次都增加叶结点），调用 rb_insert_fixup 维护红黑性质")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 刚插入新结点时，仅可能违反第四条红黑性质：每个红色结点的子结点都只能是黑色的。")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 而调整过程中，可能会违反其它性质，但都会一一修复")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("rb_insert")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insert_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前 BST 为空，则直接设置 self.bst 结点，完成插入")]),t._v("\n            new_node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_create_new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insert_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_node\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst           "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 用 ptr 指针从 root 结点（一般设为 self.bst）开始向下搜索插入位置")]),t._v("\n            ptr_p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ptr_p 记录 ptr 的父亲")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入过程中维护区间树的 max_end 属性")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr_p "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ptr 会是新结点的祖先结点，所以根据高端点 决定是否需要更新本结点的 max_end")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据低端点 (即 key) 来决定往左还是往右插入")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到了插入位置，设置新结点属性：红色、左孩子和右孩子均为哨兵 nil、父结点为 ptr_p")]),t._v("\n            new_node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_create_new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("insert_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" insert_val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 key 决定该插入到左边还是右边")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_node\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr_p"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_node\n            new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr_p\n\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_insert_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 插入后维护红黑性质")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：将结点 u 替换为结点 v（用于删除时的红黑性质保持）")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(1)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_rb_transplant")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# u 的父结点必为树结点 (红黑树性质)")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 u 是其父结点的左孩子还是右孩子，更换指针")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" u "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" v\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 无条件执行：让 v 的 parent 指针指向 u 的父结点")]),t._v("\n        v"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" u"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 辅助操作：删除之后，逐级向上进行红黑性质维护")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当删除结点 node 时，让其后继 s 替换 node。在结点被移除或者在树中移动之前，必须先记录 s 的颜色")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据当前结点的父结点、兄弟结点、兄弟结点的孩子结点的颜色，分 4 种情况，用旋转操作来调整平衡")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_rb_delete_fixup")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# if isinstance(node, TreeNode) and node != self.nil:")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当前结点 node 为真正需要被删除的结点，其祖先中有黑色结点被删除(替换)了")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的父结点必为树结点 (红黑树性质)")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 父结点是 nil，表示当前 node 为树根，只需要把根改为黑色即可")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 node 是其父结点的左孩子")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的父结点必为树结点 (红黑树性质)")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 记录 bro 为 node 父结点的右孩子，即 node 的兄弟结点")]),t._v("\n                    bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的兄弟结点必为树结点 (红黑树性质)")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 1: node 是其父结点的左孩子、其兄弟结点 bro 为红色")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 让 bro 的颜色改为黑色")]),t._v("\n                        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 确保 bro 还是 node 的兄弟结点")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bro 结点的孩子必为树结点 (红黑树性质)")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 2: 此时兄弟结点 bro 一定为黑色，如果原本不是黑色，会经过 case 1 变为黑色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时 bro 孩子均为黑色，让 bro 变为 红色")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                        node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 上移")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时 bro 的孩子不全为黑色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 3: 此时 node 是其父结点的左孩子，且兄弟结点 bro 一定为黑色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bro 的左孩子为红色，右孩子为黑色")]),t._v("\n                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改 bro 左孩子为黑色")]),t._v("\n                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改 bro 为红色（一红挂两黑）")]),t._v("\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 右旋 bro")]),t._v("\n                            bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 确保 bro 还是 node 的兄弟结点")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 3 之后，保证 bro 为黑色、bro 的右孩子为红色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 4: 此时 node 是其父结点的左孩子，且兄弟结点 bro 一定为黑色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bro 的右孩子为红色，左孩子颜色为黑色")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color\n                        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 node 是其父结点的右孩子")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的父结点必为树结点 (红黑树性质)")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 记录 bro 为 node 父结点的左孩子，即 node 的兄弟结点")]),t._v("\n                    bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 的兄弟结点必为树结点 (红黑树性质)")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 1': node 是其父结点的右孩子、其兄弟结点 bro 为红色")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 让 bro 的颜色改为黑色")]),t._v("\n                        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 确保 bro 还是 node 的兄弟结点")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bro 结点的孩子必为树结点 (红黑树性质)")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 2': 此时兄弟结点 bro 一定为黑色，如果原本不是黑色，会经过 case 1' 变为黑色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时 bro 孩子均为黑色，让 bro 变为 红色")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                        node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# node 上移")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时 bro 的孩子不全为黑色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 3': 此时 node 是其父结点的右孩子，且兄弟结点 bro 一定为黑色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bro 的左孩子为黑色，右孩子为红色")]),t._v("\n                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改 bro 右孩子为黑色")]),t._v("\n                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 修改 bro 为红色（一红挂两黑）")]),t._v("\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左旋 bro")]),t._v("\n                            bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 确保 bro 还是 node 的兄弟结点")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 3' 之后，保证 bro 为黑色、bro 的左孩子为红色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# case 4': 此时 node 是其父结点的右孩子，且兄弟结点 bro 一定为黑色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bro 的左孩子为红色，右孩子颜色为黑色")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color\n                        node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 最终将 node 的颜色置为黑色")]),t._v("\n            node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除某结点后，逐级向上维护 max_end 属性")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("_interval_delete_fix_max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除结点：输入的是被删结点 (TreeNode 类型)")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除黑色结点时，可能违反红黑性质，需要调用 rb_delete_fixup 维护红黑性质")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("interval_delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" delete_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输入的 delete_node 不合法")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'delete_node invalid!'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'提示：红黑树为空，无法继续删除。'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 通过 exact_search 精确查找树中有没有 delete_node 结点")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exact_search"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" delete_node\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" \\\n                        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当前 BST 仅有一个根结点 ptr，且欲删除根结点，会导致树空")]),t._v("\n                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("is_bst_empty "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sorted_key_list "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 正常删除结点 ptr，不会导致树变为空")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 这里的 y 主要用于记录 ptr 的后继，而 x 是覆盖了"真正被删除的结点"的结点')]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 x 覆盖了一个黑色的结点，那么在最后 需要从 x 开始向上调整红黑性质")]),t._v("\n                    y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr\n                    y_original_color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 记录 y 原始的颜色，用于最后判断是否需要维护红黑性质")]),t._v("\n\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果欲删除结点 ptr 的左右孩子均为空，则为叶，没有孩子可以覆盖 ptr")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先让 ptr 父结点的相应孩子指针指向 self.nil")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                            bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                            bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果欲删除的叶结点 ptr 为红色，那么红黑性质不会被破坏")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果欲删除的叶结点 ptr 为黑色，那么红黑性质会被破坏，其父结点的左侧"黑高"低于右侧"黑高"')]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因为原本红黑性质是满足的，所以此时 (删除 ptr 前) 只有如下这几种可能：")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. ptr 为黑、ptr 的父结点为黑")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 兄弟必存在，否则原本就不符合红黑性质了")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1. ptr 为黑、ptr 的父结点为黑、ptr 的兄弟结点为红")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 那么 bro 必有两个黑孩子，而且 bro 的黑孩子必为叶")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.1. 如果 bro 是右孩子")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 染黑、bro 的左孩子染红，然后把 bro 父结点左旋，就维护好红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.2. 如果 bro 是左孩子")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 染黑、bro 的右孩子染红，然后把 bro 父结点右旋，就维护好红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.2. ptr 为黑、ptr 的父结点为黑、ptr 的兄弟结点为黑")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 那么 bro 若有孩子，必为红孩子，而且 bro 的红孩子必为叶")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.1. 如果 bro 是右孩子，检查 bro 的孩子情况")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 的右孩子染黑，然后把 bro 父结点左旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子不存在，但左孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的左孩子染黑，然后先 bro 右旋、再原父结点左旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，原本的"黑高"为 2 定然无法维持')]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 此时将 bro 染红，然后从父结点("双黑")开始 fixup')]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_delete_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.2. 如果 bro 是左孩子，检查 bro 的孩子情况")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 的左孩子染黑，然后把 bro 父结点右旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子不存在，但右孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的右孩子染黑，然后先 bro 左旋、再原父结点右旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，而原本"黑高"为 2，定然无法维持')]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 此时将 bro 染红，然后从父结点("双黑")开始 fixup')]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_delete_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. ptr 为黑、ptr 的父结点为红")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时兄弟必存在，且为黑，否则原本就不符合红黑性质了")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 类似 1.2. 处理")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2.1. 如果 bro 是右孩子，检查 bro 的孩子情况")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子存在(必为红)")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 染红、bro 父结点和 bro 右孩子染黑，然后把 bro 父结点左旋，就维护好红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子不存在，但左孩子存在(必为红)")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的父结点染黑，然后先 bro 右旋、再原父结点左旋，就维护好红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，原本"黑高"为 1，只通过染色就可以维持')]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时将 bro 染红、父结点染黑即可")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2.2. 如果 bro 是左孩子，检查 bro 的孩子情况")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子存在(必为红)")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 染红、bro 父结点和 bro 左孩子染黑，然后把 bro 父结点右旋，就维护好红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子不存在，但右孩子存在(必为红)")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的父结点染黑，然后先 bro 左旋、再原父结点右旋，就维护好红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，原本"黑高"为 1，只通过染色就可以维持')]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时将 bro 染红、父结点染黑即可")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                    bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果进入下面的分支，ptr 不为叶")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果欲删除结点 ptr 的左孩子为空，且右孩子不为空，则将 ptr 替换为其右孩子")]),t._v("\n                        x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_transplant"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果欲删除结点 ptr 的右孩子为空，且左孩子不为空，则将 ptr 替换为其左孩子")]),t._v("\n                        x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_transplant"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 欲删除结点 ptr 的左右孩子均不为空，则将 ptr 替换为其后继")]),t._v("\n                        y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("successor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 为 ptr 的后继，y 的左孩子为 nil")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                        y_original_color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (修改)记录 y 原始的颜色")]),t._v("\n                        x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 后继结点 y 必无左孩子，让其右孩子 x 替换 y")]),t._v("\n\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 x 是哨兵 nil，意味着 y 是叶，类似前面 ptr 为叶的处理方式")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果欲删除结点 y 的左右孩子均为空，则为叶，没有孩子可以覆盖 y")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先让 y 父结点的相应孩子指针指向 self.nil")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                                bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                                bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果欲删除的叶结点 y 为红色，那么红黑性质不会被破坏")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 把 ptr 替换为其后继结点 y，并修改链接关系和 color (不修改 y 的 key、value)")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 u 是其父结点的左孩子还是右孩子，更换指针")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 让 y 的 parent 指针指向 ptr 的父结点")]),t._v("\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                                y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 继承 ptr 的颜色")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果欲删除的叶结点 y 为黑色，那么红黑性质会被破坏，其父结点的左侧"黑高"低于右侧"黑高"')]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 因为原本红黑性质是满足的，所以此时 (删除 y 前) 只有如下这几种可能：")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1. y 为黑、y 的父结点为黑")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 兄弟必存在，否则原本就不符合红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1. y 为黑、y 的父结点为黑、y 的兄弟结点为红")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 那么 bro 必有两个黑孩子，而且 bro 的黑孩子必为叶")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.1. 如果 bro 是右孩子")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 染黑、bro 的左孩子染红，然后把 bro 父结点左旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.2. 如果 bro 是左孩子")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 染黑、bro 的右孩子染红，然后把 bro 父结点右旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.2. y 为黑、y 的父结点为黑、y 的兄弟结点为黑")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 那么 bro 若有孩子，必为红孩子，而且 bro 的红孩子必为叶")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.1. 如果 bro 是右孩子，检查 bro 的孩子情况")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子存在(必为红)")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 的右孩子染黑，然后把 bro 父结点左旋，就维护好红黑性质了")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子不存在，但左孩子存在(必为红)")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的左孩子染黑，然后先 bro 右旋、再原父结点左旋，就维护好红黑性质了")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                            new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，原本的"黑高"为 2 定然无法维持')]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 此时将 bro 染红，然后从父结点("双黑")开始 fixup')]),t._v("\n                                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_delete_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1.1.2. 如果 bro 是左孩子，检查 bro 的孩子情况")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子存在(必为红)")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时只需要把 bro 的左孩子染黑，然后把 bro 父结点右旋，就维护好红黑性质了")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子不存在，但右孩子存在(必为红)")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的右孩子染黑，然后先 bro 左旋、再原父结点右旋，就维护好红黑性质了")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                            new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，而原本"黑高"为 2，定然无法维持')]),t._v("\n                                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 此时将 bro 染红，然后从父结点("双黑")开始 fixup')]),t._v("\n                                            bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_delete_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2. y 为黑、y 的父结点为红")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时兄弟必存在，且为黑，否则原本就不符合红黑性质了")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 类似 1.2. 处理")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2.1. 如果 bro 是右孩子，检查 bro 的孩子情况")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 染红、bro 父结点和 bro 右孩子染黑，然后把 bro 父结点左旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的右孩子不存在，但左孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的父结点染黑，然后先 bro 右旋、再原父结点左旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，原本"黑高"为 1，只通过染色就可以维持')]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时将 bro 染红、父结点染黑即可")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 2.2. 如果 bro 是左孩子，检查 bro 的孩子情况")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 染红、bro 父结点和 bro 左孩子染黑，然后把 bro 父结点右旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 bro 的左孩子不存在，但右孩子存在(必为红)")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 则此时把 bro 的父结点染黑，然后先 bro 左旋、再原父结点右旋，就维护好红黑性质了")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n                                        new_bro "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_left_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_right_rotate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 如果 bro 的左右孩子都不存在，原本"黑高"为 1，只通过染色就可以维持')]),t._v("\n                                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时将 bro 染红、父结点染黑即可")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                                        bro"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 把 ptr 替换为其后继结点 y，并修改链接关系和 color (不修改 y 的 key、value)")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("or")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 根据 u 是其父结点的左孩子还是右孩子，更换指针")]),t._v("\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ptr "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                                    ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 让 y 的 parent 指针指向 ptr 的父结点")]),t._v("\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 继承 ptr 的颜色")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 此时后继 y 一定有右孩子，x 不可能为 self.nil")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 ptr 的后继 y 就是 ptr 的直接右孩子")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                            x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果 ptr 的后继 y 不是 ptr 的直接右孩子")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 让 y 被其右孩子替换（因为之后 y 要用于替换 ptr）")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 所以替换了 y 的结点就是 y.right，也即 x")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("assert")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil\n                            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_transplant"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                            y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 现在把 ptr 替换为其后继结点 y，并修改链接关系和 color (不修改 y 的 key、value)")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_transplant"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                        y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n                        y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                        y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n                        y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y\n                        y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ptr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("color  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# y 继承 ptr 的颜色")]),t._v("\n                        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 逐级向上修改 max_end")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_interval_delete_fix_max"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# 最后，如果"真正"删除的结点颜色为黑色，则破坏了红黑性质，需要进行维护')]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" y_original_color"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_rb_delete_fixup"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除后维护红黑性质")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找不到目标结点")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找不到目标结点，删除失败'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到一棵以 root 为根的 BST/RBT 中的最小值结点（一路向左）")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("min_bst")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" root "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                root "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" root\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到一棵以 root 为根的 BST/RBT 中的最大值结点（一路向右）")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("max_bst")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" root "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                root "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" root\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到在 BST 中 node 结点的前驱结点，即：其左子树中的最大值")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("predecessor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("max_bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到在 BST 中 node 结点的后继结点，即：其右子树中的最小值")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 时间复杂度 O(log n) 与树高有关")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("successor")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("min_bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 检查一棵以 root 为根的二叉树是否为 BST")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("check_bst")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当前结点非树结点，不合法")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("elif")]),t._v(" root "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nil"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 当前结点为哨兵，空树也算作是 BST")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左/右孩子为空时，左/右孩子满足 BST 条件")]),t._v("\n            left_bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左孩子是否满足 BST 条件")]),t._v("\n            right_bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 右孩子是否满足 BST 条件")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前结点的左孩子不为空，检查该左孩子的值")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果左孩子的值小于等于当前结点的值，表示满足 BST 条件，继续往左观察")]),t._v("\n                    left_bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("check_bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("left"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果左孩子的值大于当前结点的值，表示不满足 BST 条件")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果当前结点的右孩子不为空，检查该右孩子的值")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果右孩子的值大于当前结点的值，表示满足 BST 条件，继续往右观察")]),t._v("\n                    right_bst "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("check_bst"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("right"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果右孩子的值小于等于当前结点的值，表示不满足 BST 条件")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 左右孩子都满足条件，才返回 True")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" left_bst "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" right_bst\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 以插入的方式，构建 BST/RBT")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# kv_array 为二维数组，内维度的数组，首元素为 key，次元素为 value，可以为任意对象")]),t._v("\n    kv_array "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("300")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("400")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("23")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("17")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("600")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("26")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("26")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("700")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("800")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("900")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# kv_array = [[(i, i << 1), 100 * i] for i in range(1000)]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# kv_array = [[(i, i << 1), 100 * i] for i in reversed(range(1000))]")]),t._v("\n\n    node_array "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" kv "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" kv_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("kv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 像这种 key 基本有序地插入，如果是普通的 BST，那么树结构会退化地很严重，大幅影响效率")]),t._v("\n    start "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("process_time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# inter_tree = IntervalTree(kv_array)")]),t._v("\n    inter_tree "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" IntervalTree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("process_time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'建立 Red-Black Tree 耗时: %.5f ms'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出升序排序的结果")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [0, 5, 6, 8, 15, 16, 17, 19, 25, 26]")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 区间搜索")]),t._v("\n    search_interval "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    start "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("process_time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ans "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_search"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("process_time"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ans "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找到了与 interval'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'有重叠的区间'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'，其值为:'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找不到与 interval'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'有重叠的区间'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Running Time: %.5f ms'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" start"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删除结点")]),t._v("\n    inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_delete"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找不到")]),t._v("\n\n    delete_nodes "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" node_array\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" delete_node "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" delete_nodes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_delete"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("delete_node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删空之后测试再删")]),t._v("\n    inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_delete"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 提示 BST 为空")]),t._v("\n    inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 删空之后测试查找")]),t._v("\n    search_interval "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ans "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_search"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找不到")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ans "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找到了与 interval'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'有重叠的区间'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'，其值为:'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找不到与 interval'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'有重叠的区间'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 重新动态增加")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" node "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("reversed")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node_array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_insert"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("node"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("update_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_sorted_key_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 再次测试区间搜索")]),t._v("\n    search_interval "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    ans "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inter_tree"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interval_search"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" ans "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("is")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" TreeNode"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找到了与 interval'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'有重叠的区间'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inter"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'，其值为:'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ans"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("val"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'找不到与 interval'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" search_interval"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'有重叠的区间'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" __name__ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"__main__"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    sys"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),n("h2",{attrs:{id:"参考资料"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),n("ul",[n("li",[t._v("Introduction to Algorithm (aka CLRS) Third Edition - Chapter 14")])])])}),[],!1,null,null,null);s.default=e.exports}}]);