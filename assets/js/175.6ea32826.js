(window.webpackJsonp=window.webpackJsonp||[]).push([[175],{434:function(e,t,r){"use strict";r.r(t);var a=r(28),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"ai-tasks-datasets"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#ai-tasks-datasets"}},[e._v("#")]),e._v(" AI Tasks & Datasets")]),e._v(" "),r("p",[e._v("By "),r("a",{attrs:{href:"https://yuweiyin.github.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("YuweiYin"),r("OutboundLink")],1)]),e._v(" "),r("h2",{attrs:{id:"nlp-natural-language-processing"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#nlp-natural-language-processing"}},[e._v("#")]),e._v(" NLP - Natural Language Processing")]),e._v(" "),r("h3",{attrs:{id:"glue-general-language-understanding-evaluation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#glue-general-language-understanding-evaluation"}},[e._v("#")]),e._v(" GLUE - General Language Understanding Evaluation")]),e._v(" "),r("table",[r("thead",[r("tr",[r("th",{staticStyle:{"text-align":"center"}},[e._v("DataSet")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("Full Name")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("Task")])])]),e._v(" "),r("tbody",[r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("CoLA")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Corpus of Linguistic Acceptability")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}})]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("SST-2")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Stanford Sentiment Treebank")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Sentiment analysis")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("MRPC")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Microsoft Research Paraphrase Corpus")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic textual similarity")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("STS-B")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic Textual Similarity")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic textual similarity")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("QQP")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Quora Question Pairs")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Semantic textual similarity/Paraphrase identification")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("RTE")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Recognizing Texual Entailment")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("MNLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Multi-Genre NLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("QNLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Question NLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("WNLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Winograd NLI")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("Natural language inference")])])])]),e._v(" "),r("ul",[r("li",[e._v("Links:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1804.07461.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("GLUE paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://gluebenchmark.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("GLUE dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e",target:"_blank",rel:"noopener noreferrer"}},[e._v("GLUE Download Script"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://w4ngatang.github.io/static/papers/superglue.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"cola-the-corpus-of-linguistic-acceptability"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#cola-the-corpus-of-linguistic-acceptability"}},[e._v("#")]),e._v(" CoLA - The Corpus of Linguistic Acceptability")]),e._v(" "),r("p",[e._v("CoLA: Given a sentence, judge if its grammar is correct. (Yes or No)")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1805.12471.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("CoLA paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://nyu-mll.github.io/CoLA/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CoLA dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.nyu.edu/projects/bowman/xnli/XNLI-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: cola_public 1.0"),r("OutboundLink")],1),e._v(" (260 KB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://s3.amazonaws.com/xnli/XNLI-MT-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: cola_public 1.1"),r("OutboundLink")],1),e._v(" (255 KB, ZIP)")])])])]),e._v(" "),r("h3",{attrs:{id:"sst-stanford-sentiment-treebank"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sst-stanford-sentiment-treebank"}},[e._v("#")]),e._v(" SST - Stanford Sentiment Treebank")]),e._v(" "),r("p",[e._v("SST: Given a sentence, especially a movie comment, decide its sentiment category. (SST-2 has 2 categories, while SST-5 has 5 categories)")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("SST paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/sentiment/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("SST dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Main zip file with readme"),r("OutboundLink")],1),e._v(" (6.4 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://nlp.stanford.edu/~socherr/stanfordSentimentTreebankRaw.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Dataset raw counts"),r("OutboundLink")],1),e._v(" (4.8 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Train, Dev, Test Splits in PTB Tree Format"),r("OutboundLink")],1),e._v(" (790 KB, ZIP)")])])])]),e._v(" "),r("h3",{attrs:{id:"mrpc-microsoft-research-paraphrase-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#mrpc-microsoft-research-paraphrase-corpus"}},[e._v("#")]),e._v(" MRPC - Microsoft Research Paraphrase Corpus")]),e._v(" "),r("p",[e._v("MRPC: Given two sentences, judge if they have the same meaning. (5000+ pairs)")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d3/data/pdf/anthology-PDF/C/C04/C04-1051.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("MRPC paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.microsoft.com/en-us/download/confirmation.aspx?id=52398",target:"_blank",rel:"noopener noreferrer"}},[e._v("MRPC Download"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"sts-semantic-textual-similarity"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sts-semantic-textual-similarity"}},[e._v("#")]),e._v(" STS - Semantic Textual Similarity")]),e._v(" "),r("p",[e._v("Evaluate the similarity between two sentences by Semantic Textual Similarity (STS).")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1708.00055.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("STS paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark",target:"_blank",rel:"noopener noreferrer"}},[e._v("STS Download"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"nli-natural-language-inference"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#nli-natural-language-inference"}},[e._v("#")]),e._v(" NLI - Natural Language Inference")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1809.05053.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("XNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.nyu.edu/projects/bowman/multinli/paper.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("MultiNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/pubs/snli_paper.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("SNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://papers.nips.cc/paper/8163-e-snli-natural-language-inference-with-natural-language-explanations.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("e-SNLI paper"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1808.06752.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI paper"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.nyu.edu/projects/bowman/xnli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("XNLI dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.nyu.edu/projects/bowman/multinli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MultiNLI dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/projects/snli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("SNLI dataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://jgc128.github.io/mednli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.nyu.edu/projects/bowman/xnli/XNLI-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: XNLI 1.0"),r("OutboundLink")],1),e._v(" (17 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://s3.amazonaws.com/xnli/XNLI-MT-1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: XNLI-MT 1.0"),r("OutboundLink")],1),e._v(" (445 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.nyu.edu/projects/bowman/multinli/multinli_1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: MultiNLI 1.0"),r("OutboundLink")],1),e._v(" (227 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"https://nlp.stanford.edu/projects/snli/snli_1.0.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: SNLI 1.0"),r("OutboundLink")],1),e._v(" (~100 MB, ZIP)")]),e._v(" "),r("li",[r("a",{attrs:{href:"http://doi.org/10.13026/C2RS98",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: MedNLI"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Source Code:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/OanaMariaCamburu/e-SNLI",target:"_blank",rel:"noopener noreferrer"}},[e._v("e-SNLI code"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://archive.physionet.org/physiotools/mimic-code/mednli/",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI code"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://github.com/jgc128/mednli_baseline",target:"_blank",rel:"noopener noreferrer"}},[e._v("MedNLI baseline"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"squad"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#squad"}},[e._v("#")]),e._v(" SQuAD")]),e._v(" "),r("p",[e._v("SQuAD: Machine Reading Comprehension (MRC) dataset presented by Stanford University in 2016. Given a passage and several questions, the model needs to answer all the questions. (500+ passages and 100,000+ questions)")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/abs/1606.05250",target:"_blank",rel:"noopener noreferrer"}},[e._v("SQuAD 1"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://arxiv.org/abs/1806.03822",target:"_blank",rel:"noopener noreferrer"}},[e._v("SQuAD 2"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Link:\n"),r("ul",[r("li",[e._v("https://rajpurkar.github.io/SQuAD-explorer/")])])])]),e._v(" "),r("h3",{attrs:{id:"wikitext"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wikitext"}},[e._v("#")]),e._v(" WikiText")]),e._v(" "),r("p",[e._v("WikiText: The WikiText Long Term Dependency Language Modeling Dataset. It contains 100 million English words. WikiText-2 is two times the size of Penn Treebank (PTB) and WikiText-103 is 110 times the size of PTB.")]),e._v(" "),r("ul",[r("li",[e._v("Link:\n"),r("ul",[r("li",[e._v("http://metamind.io/research/the-wikitext-long-term-dependency-language-modeling-dataset/")]),e._v(" "),r("li",[e._v("https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip")])])])]),e._v(" "),r("h3",{attrs:{id:"imdb"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#imdb"}},[e._v("#")]),e._v(" IMDB")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Learning Word Vectors for Sentiment Analysis"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ai.stanford.edu/~amaas/data/sentiment/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Large Movie Review Dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ai.stanford.edu/~amaas/data/sentiment/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Large Movie Review Dataset v1.0"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"sentiment140"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#sentiment140"}},[e._v("#")]),e._v(" Sentiment140")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Twitter Sentiment Classification using Distant Supervision"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://help.sentiment140.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sentiment140"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://help.sentiment140.com/for-students",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sentiment140 For Academics"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Stanford link"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://docs.google.com/file/d/0B04GJPshIjmPRnZManQwWEdTZjg/edit",target:"_blank",rel:"noopener noreferrer"}},[e._v("Google Drive link"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"wordnet"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wordnet"}},[e._v("#")]),e._v(" WordNet")]),e._v(" "),r("ul",[r("li",[e._v("WordNet Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://mitpress.mit.edu/books/wordnet",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet An Electronic Lexical Database"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://wordnet.princeton.edu/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://wordnet.princeton.edu/download/current-version",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet current version"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://wordnet.princeton.edu/download/old-versions",target:"_blank",rel:"noopener noreferrer"}},[e._v("WordNet old version"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"the-wikipedia-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#the-wikipedia-corpus"}},[e._v("#")]),e._v(" The Wikipedia Corpus")]),e._v(" "),r("ul",[r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.english-corpora.org/wiki/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Wikipedia Corpus"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.corpusdata.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Full-text corpus data"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"the-blog-authorship-corpus"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#the-blog-authorship-corpus"}},[e._v("#")]),e._v(" The Blog Authorship Corpus")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.cs.biu.ac.il/~schlerj/schler_springsymp06.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Effects of Age and Gender on Blogging"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Blog Authorship Corpus"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.cs.biu.ac.il/~koppel/blogs/blogs.zip",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: The Blog Authorship Corpus"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"wmt-statistical-machine-translation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#wmt-statistical-machine-translation"}},[e._v("#")]),e._v(" WMT - Statistical Machine Translation")]),e._v(" "),r("p",[r("a",{attrs:{href:"http://www.statmt.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Statistical Machine Translation"),r("OutboundLink")],1)]),e._v(" "),r("ul",[r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt19/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WMT 19"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt20/",target:"_blank",rel:"noopener noreferrer"}},[e._v("WMT 20"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://statmt.org/europarl/",target:"_blank",rel:"noopener noreferrer"}},[e._v("uropean Parliament Proceedings Parallel Corpus 1996-2011"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt19/translation-task.html#download",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download WMT19"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.statmt.org/wmt20/translation-task.html#download",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download WMT20"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"uci-s-spambase"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#uci-s-spambase"}},[e._v("#")]),e._v(" UCI's Spambase")]),e._v(" "),r("p",[e._v("UCI: a large scale spam email dataset.")]),e._v(" "),r("ul",[r("li",[e._v("Link: https://archive.ics.uci.edu/ml/datasets/Spambase")])]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"计算机视觉-cv-computer-vision"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#计算机视觉-cv-computer-vision"}},[e._v("#")]),e._v(" 计算机视觉 CV - Computer Vision")]),e._v(" "),r("h3",{attrs:{id:"mnist"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#mnist"}},[e._v("#")]),e._v(" MNIST")]),e._v(" "),r("p",[e._v("MNIST: comes from National Institute of Standards and Technology (NIST). Its training set consists of handwriting digits by 250 different people, including 50% high school students and the staff of the Census Bureau. Its test set is also handwriting digits. (10 categories)")]),e._v(" "),r("ul",[r("li",[e._v("Links:\n"),r("ul",[r("li",[e._v("http://pjreddie.com/projects/mnist-in-csv/")]),e._v(" "),r("li",[e._v("http://yann.lecun.com/exdb/mnist/")])])])]),e._v(" "),r("h3",{attrs:{id:"fashion-mnist"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#fashion-mnist"}},[e._v("#")]),e._v(" Fashion-MNIST")]),e._v(" "),r("p",[e._v("Fashion-MNIST: is similar to MNIST and includes 60,000 training images and 10,000 testing images (fashion product images; 10 categories)")]),e._v(" "),r("ul",[r("li",[e._v("Links:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/zalandoresearch/fashion-mnist",target:"_blank",rel:"noopener noreferrer"}},[e._v("fashion-mnist Github"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"cifar-10"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#cifar-10"}},[e._v("#")]),e._v(" CIFAR-10")]),e._v(" "),r("p",[e._v("CIFAR-10: includes 60,000 32x32 color images, averagely divided into 10 categories (10 * 6,000). It has 50,000 training images and 10,000 test images.")]),e._v(" "),r("ul",[r("li",[e._v("Link: https://www.cs.toronto.edu/~kriz/cifar.html")])]),e._v(" "),r("h3",{attrs:{id:"imagenet"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#imagenet"}},[e._v("#")]),e._v(" ImageNet")]),e._v(" "),r("p",[e._v("ImageNet: a famous large-scale image dataset and computer vision competition. It has a subset MiniImageNet.")]),e._v(" "),r("ul",[r("li",[e._v("Link: http://image-net.org/")])]),e._v(" "),r("h3",{attrs:{id:"open-images-dataset-v4"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#open-images-dataset-v4"}},[e._v("#")]),e._v(" Open Images Dataset V4")]),e._v(" "),r("ul",[r("li",[e._v("Link: https://github.com/openimages/dataset")])]),e._v(" "),r("h3",{attrs:{id:"coco-common-objects-in-context"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#coco-common-objects-in-context"}},[e._v("#")]),e._v(" COCO - Common Objects in Context")]),e._v(" "),r("ul",[r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://cocodataset.org/#home",target:"_blank",rel:"noopener noreferrer"}},[e._v("Common Objects in Context"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://cocodataset.org/#download",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: Images & Annotations"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Source Code:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://github.com/cocodataset",target:"_blank",rel:"noopener noreferrer"}},[e._v("cocodataset"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://github.com/cocodataset/cocoapi",target:"_blank",rel:"noopener noreferrer"}},[e._v("cocoapi"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"vqa-visual-qa"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#vqa-visual-qa"}},[e._v("#")]),e._v(" VQA - Visual QA")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://arxiv.org/pdf/1612.00837.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://visualqa.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Visual QA"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://visualqa.org/vqa_v1_download.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: VQA v1"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://visualqa.org/download.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: VQA v2"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"visual-genome"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#visual-genome"}},[e._v("#")]),e._v(" Visual Genome")]),e._v(" "),r("p",[e._v("Visual Genome: an image dataset with 100,000 images. Its images contain more details compared to the images of ImageNet.")]),e._v(" "),r("ul",[r("li",[e._v("Link: http://visualgenome.org/")])]),e._v(" "),r("h3",{attrs:{id:"svhn-street-view-house-numbers"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#svhn-street-view-house-numbers"}},[e._v("#")]),e._v(" SVHN - Street View House Numbers")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reading Digits in Natural Images with Unsupervised Feature Learning"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Street View House Numbers (SVHN) Dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[e._v("Format 1: Full Numbers\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/train.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: train.tar.gz"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/test.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: test.tar.gz"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/extra.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: extra.tar.gz"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Format 2: Cropped Digits\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/train_32x32.mat",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: train_32x32.mat"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/test_32x32.mat",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: test_32x32.mat"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: extra_32x32.mat"),r("OutboundLink")],1)])])])])])]),e._v(" "),r("hr"),e._v(" "),r("h2",{attrs:{id:"speech"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#speech"}},[e._v("#")]),e._v(" Speech")]),e._v(" "),r("h3",{attrs:{id:"librispeech"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#librispeech"}},[e._v("#")]),e._v(" LibriSpeech")]),e._v(" "),r("p",[e._v("LibriSpeech: a large-scale speech dataset with 1,000 hours Englsih audio.")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.danielpovey.com/files/2015_icassp_librispeech.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("LibriSpeech: an ASR corpus based on public domain audio books"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.openslr.org/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Open Speech and Language Resources"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/12/",target:"_blank",rel:"noopener noreferrer"}},[e._v("LibriSpeech ASR corpus"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/dev-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("dev-clean.tar.gz"),r("OutboundLink")],1),e._v(' [337M]   (development set, "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/dev-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/dev-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("dev-other.tar.gz"),r("OutboundLink")],1),e._v(' [314M]   (development set, "other", more challenging, speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/dev-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/test-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("test-clean.tar.gz"),r("OutboundLink")],1),e._v(' [346M]   (test set, "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/test-clean.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/test-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("test-other.tar.gz"),r("OutboundLink")],1),e._v(' [328M]   (test set, "other" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/test-other.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/train-clean-100.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("train-clean-100.tar.gz"),r("OutboundLink")],1),e._v(' [6.3G]   (training set of 100 hours "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/train-clean-100.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/train-clean-360.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("train-clean-360.tar.gz"),r("OutboundLink")],1),e._v(' [23G]   (training set of 360 hours "clean" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/train-clean-360.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/train-other-500.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("train-other-500.tar.gz"),r("OutboundLink")],1),e._v(' [30G]   (training set of 500 hours "other" speech )   Mirrors: '),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/train-other-500.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/intro-disclaimers.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("intro-disclaimers.tar.gz"),r("OutboundLink")],1),e._v(" [695M]   (extracted LibriVox announcements for some of the speakers )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/intro-disclaimers.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/original-mp3.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("original-mp3.tar.gz"),r("OutboundLink")],1),e._v(" [87G]   (LibriVox mp3 files, from which corpus' audio was extracted )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/original-mp3.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/original-books.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("original-books.tar.gz"),r("OutboundLink")],1),e._v(" [297M]   (Project Gutenberg texts, against which the audio in the corpus was aligned )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/original-books.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/raw-metadata.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("raw-metadata.tar.gz"),r("OutboundLink")],1),e._v(" [33M]   (Some extra meta-data produced during the creation of the corpus )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/raw-metadata.tar.gz",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.openslr.org/resources/12/md5sum.txt",target:"_blank",rel:"noopener noreferrer"}},[e._v("md5sum.txt"),r("OutboundLink")],1),e._v(" [600 bytes]   (MD5 checksums for the archive files )   Mirrors: "),r("a",{attrs:{href:"http://cn-mirror.openslr.org/resources/12/md5sum.txt",target:"_blank",rel:"noopener noreferrer"}},[e._v("China"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"voxceleb"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#voxceleb"}},[e._v("#")]),e._v(" VoxCeleb")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.robots.ox.ac.uk/~vgg/publications/2017/Nagrani17/nagrani17.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb: a large-scale speaker identification dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb1"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("VoxCeleb2"),r("OutboundLink")],1)])])])]),e._v(" "),r("h3",{attrs:{id:"voxforge"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#voxforge"}},[e._v("#")]),e._v(" VoxForge")]),e._v(" "),r("p",[e._v("VoxForge: a speech dataset. Its audio contains accents from different people.")]),e._v(" "),r("ul",[r("li",[e._v("Link: http://www.voxforge.org/")])]),e._v(" "),r("h3",{attrs:{id:"msd-million-song-dataset"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#msd-million-song-dataset"}},[e._v("#")]),e._v(" MSD - Million Song Dataset")]),e._v(" "),r("ul",[r("li",[e._v("Paper Link:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://www.deepdyve.com/lp/association-for-computing-machinery/the-million-song-dataset-challenge-C1ThXUlRZH",target:"_blank",rel:"noopener noreferrer"}},[e._v("The Million Song Dataset Challenge"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Homepage:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://millionsongdataset.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Million Song Dataset"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Dataset Download:\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://millionsongdataset.com/pages/getting-dataset/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Download: MSD"),r("OutboundLink")],1)])])])]),e._v(" "),r("hr"),e._v(" "),r("ul",[r("li",[r("strong",[e._v("TODO")]),e._v(" "),r("ul",[r("li",[e._v("More detailed dataset description. (e.g., the amount of data entries, sample data, etc.)")]),e._v(" "),r("li",[e._v("Related classical and the state-of-the-art models (with performance table).")])])])])])}),[],!1,null,null,null);t.default=n.exports}}]);